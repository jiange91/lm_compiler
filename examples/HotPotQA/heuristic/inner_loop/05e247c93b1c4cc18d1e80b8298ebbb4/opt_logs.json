{
    "0171a75bac4540bc99c793ca6be763c4": {
        "id": "0171a75bac4540bc99c793ca6be763c4",
        "bo_trial_id": 0,
        "params": {
            "generate_query_lm_model": "openai_gpt-4o-mini",
            "refine_query_sampler_0_lm_model": "openai_gpt-4o-mini",
            "refine_query_sampler_0_reasoning": "ZeroShotCoT",
            "refine_query_sampler_1_lm_model": "openai_gpt-4o-mini",
            "refine_query_sampler_1_reasoning": "ZeroShotCoT",
            "refine_query_sampler_2_lm_model": "openai_gpt-4o-mini",
            "refine_query_sampler_2_reasoning": "ZeroShotCoT",
            "refine_query_aggregator_lm_model": "openai_gpt-4o-mini",
            "refine_query_aggregator_reasoning": "ZeroShotCoT",
            "generate_answer_sampler_0_lm_model": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
            "generate_answer_sampler_0_reasoning": "ZeroShotCoT",
            "generate_answer_sampler_1_lm_model": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
            "generate_answer_sampler_1_reasoning": "ZeroShotCoT",
            "generate_answer_sampler_2_lm_model": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
            "generate_answer_sampler_2_reasoning": "ZeroShotCoT",
            "generate_answer_aggregator_lm_model": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
            "generate_answer_aggregator_reasoning": "ZeroShotCoT"
        },
        "score": 0.0,
        "price": 0.0025929499999999997,
        "eval_cost": 0.0025929499999999997,
        "eval_task": {
            "script_path": "/mnt/ssd4/lm_compiler/examples/HotPotQA/cognify_anno.py",
            "args": [],
            "other_python_paths": [],
            "module_name_paths": {
                "refine_query": "refine_query_ensemble_universal_self_consistency",
                "generate_answer": "generate_answer_ensemble_universal_self_consistency"
            },
            "aggregated_proposals": {
                "outer_loop": {
                    "refine_query": [
                        [
                            "ensemble",
                            "universal_self_consistency"
                        ]
                    ],
                    "generate_answer": [
                        [
                            "ensemble",
                            "universal_self_consistency"
                        ]
                    ]
                },
                "inner_loop": {
                    "generate_query": [
                        [
                            "lm_model",
                            "openai_gpt-4o-mini"
                        ]
                    ],
                    "refine_query_sampler_0": [
                        [
                            "lm_model",
                            "openai_gpt-4o-mini"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "refine_query_sampler_1": [
                        [
                            "lm_model",
                            "openai_gpt-4o-mini"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "refine_query_sampler_2": [
                        [
                            "lm_model",
                            "openai_gpt-4o-mini"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "refine_query_aggregator": [
                        [
                            "lm_model",
                            "openai_gpt-4o-mini"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "generate_answer_sampler_0": [
                        [
                            "lm_model",
                            "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "generate_answer_sampler_1": [
                        [
                            "lm_model",
                            "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "generate_answer_sampler_2": [
                        [
                            "lm_model",
                            "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ],
                    "generate_answer_aggregator": [
                        [
                            "lm_model",
                            "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct"
                        ],
                        [
                            "reasoning",
                            "ZeroShotCoT"
                        ]
                    ]
                }
            },
            "all_params_ser": {
                "refine_query_ensemble": {
                    "name": "ensemble",
                    "module_name": "refine_query",
                    "options": {
                        "universal_self_consistency": {
                            "name": "universal_self_consistency",
                            "type": "UniversalSelfConsistency",
                            "num_path": 3,
                            "temperature": 0.7
                        }
                    },
                    "default_option": "universal_self_consistency",
                    "type": "ModuleEnsemble"
                },
                "generate_answer_ensemble": {
                    "name": "ensemble",
                    "module_name": "generate_answer",
                    "options": {
                        "universal_self_consistency": {
                            "name": "universal_self_consistency",
                            "type": "UniversalSelfConsistency",
                            "num_path": 3,
                            "temperature": 0.7
                        }
                    },
                    "default_option": "universal_self_consistency",
                    "type": "ModuleEnsemble"
                },
                "generate_query_lm_model": {
                    "name": "lm_model",
                    "module_name": "generate_query",
                    "options": {
                        "openai_gpt-4o-mini": {
                            "name": "openai_gpt-4o-mini",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "openai",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "gpt-4o-mini"
                                }
                            }
                        }
                    },
                    "default_option": "openai_gpt-4o-mini",
                    "type": "LMSelection"
                },
                "refine_query_sampler_0_lm_model": {
                    "name": "lm_model",
                    "module_name": "refine_query_sampler_0",
                    "options": {
                        "openai_gpt-4o-mini": {
                            "name": "openai_gpt-4o-mini",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "openai",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "gpt-4o-mini"
                                }
                            }
                        }
                    },
                    "default_option": "openai_gpt-4o-mini",
                    "type": "LMSelection"
                },
                "refine_query_sampler_0_reasoning": {
                    "name": "reasoning",
                    "module_name": "refine_query_sampler_0",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "refine_query_sampler_1_lm_model": {
                    "name": "lm_model",
                    "module_name": "refine_query_sampler_1",
                    "options": {
                        "openai_gpt-4o-mini": {
                            "name": "openai_gpt-4o-mini",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "openai",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "gpt-4o-mini"
                                }
                            }
                        }
                    },
                    "default_option": "openai_gpt-4o-mini",
                    "type": "LMSelection"
                },
                "refine_query_sampler_1_reasoning": {
                    "name": "reasoning",
                    "module_name": "refine_query_sampler_1",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "refine_query_sampler_2_lm_model": {
                    "name": "lm_model",
                    "module_name": "refine_query_sampler_2",
                    "options": {
                        "openai_gpt-4o-mini": {
                            "name": "openai_gpt-4o-mini",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "openai",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "gpt-4o-mini"
                                }
                            }
                        }
                    },
                    "default_option": "openai_gpt-4o-mini",
                    "type": "LMSelection"
                },
                "refine_query_sampler_2_reasoning": {
                    "name": "reasoning",
                    "module_name": "refine_query_sampler_2",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "refine_query_aggregator_lm_model": {
                    "name": "lm_model",
                    "module_name": "refine_query_aggregator",
                    "options": {
                        "openai_gpt-4o-mini": {
                            "name": "openai_gpt-4o-mini",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "openai",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "gpt-4o-mini"
                                }
                            }
                        }
                    },
                    "default_option": "openai_gpt-4o-mini",
                    "type": "LMSelection"
                },
                "refine_query_aggregator_reasoning": {
                    "name": "reasoning",
                    "module_name": "refine_query_aggregator",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "generate_answer_sampler_0_lm_model": {
                    "name": "lm_model",
                    "module_name": "generate_answer_sampler_0",
                    "options": {
                        "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct": {
                            "name": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "fireworks",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "accounts/fireworks/models/llama-v3p2-3b-instruct"
                                }
                            }
                        }
                    },
                    "default_option": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                    "type": "LMSelection"
                },
                "generate_answer_sampler_0_reasoning": {
                    "name": "reasoning",
                    "module_name": "generate_answer_sampler_0",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "generate_answer_sampler_1_lm_model": {
                    "name": "lm_model",
                    "module_name": "generate_answer_sampler_1",
                    "options": {
                        "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct": {
                            "name": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "fireworks",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "accounts/fireworks/models/llama-v3p2-3b-instruct"
                                }
                            }
                        }
                    },
                    "default_option": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                    "type": "LMSelection"
                },
                "generate_answer_sampler_1_reasoning": {
                    "name": "reasoning",
                    "module_name": "generate_answer_sampler_1",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "generate_answer_sampler_2_lm_model": {
                    "name": "lm_model",
                    "module_name": "generate_answer_sampler_2",
                    "options": {
                        "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct": {
                            "name": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "fireworks",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "accounts/fireworks/models/llama-v3p2-3b-instruct"
                                }
                            }
                        }
                    },
                    "default_option": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                    "type": "LMSelection"
                },
                "generate_answer_sampler_2_reasoning": {
                    "name": "reasoning",
                    "module_name": "generate_answer_sampler_2",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                },
                "generate_answer_aggregator_lm_model": {
                    "name": "lm_model",
                    "module_name": "generate_answer_aggregator",
                    "options": {
                        "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct": {
                            "name": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                            "type": "ModelOption",
                            "model_config": {
                                "provider": "fireworks",
                                "cost_indicator": 1.0,
                                "kwargs": {
                                    "model": "accounts/fireworks/models/llama-v3p2-3b-instruct"
                                }
                            }
                        }
                    },
                    "default_option": "fireworks_accounts/fireworks/models/llama-v3p2-3b-instruct",
                    "type": "LMSelection"
                },
                "generate_answer_aggregator_reasoning": {
                    "name": "reasoning",
                    "module_name": "generate_answer_aggregator",
                    "options": {
                        "ZeroShotCoT": {
                            "name": "ZeroShotCoT",
                            "type": "ZeroShotCoT"
                        }
                    },
                    "default_option": "ZeroShotCoT",
                    "type": "LMReasoning"
                }
            }
        }
    }
}