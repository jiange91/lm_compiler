{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd4/lm_compiler/my_env/lib/python3.12/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/mnt/ssd4/lm_compiler/my_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd4/lm_compiler/examples/HotPotQA/cache/compiler\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['DSP_CACHEBOOL'] = 'false'\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(os.getcwd(), 'cache')\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from compiler.utils import load_api_key\n",
    "\n",
    "load_api_key('/mnt/ssd4/lm_compiler/secrets.toml')\n",
    "\n",
    "gpt4o_mini = dspy.OpenAI('gpt-4o-mini', max_tokens=1000)\n",
    "colbert = dspy.ColBERTv2(url='http://192.168.1.18:8893/api/search')\n",
    "dspy.configure(lm=gpt4o_mini, rm=colbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'Are both Cangzhou and Qionghai in the Hebei province of China?', 'answer': 'no', 'gold_titles': {'Cangzhou', 'Qionghai'}}) (input_keys={'question'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = HotPotQA(train_seed=1, train_size=150, eval_seed=2023, dev_size=200, test_size=0)\n",
    "trainset = [x.with_inputs('question') for x in dataset.train[0:100]]\n",
    "valset = [x.with_inputs('question') for x in dataset.train[100:150]]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "# show an example datapoint; it's just a question-answer pair\n",
    "devset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "class BasicMH(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_query = [dspy.ChainOfThought(\"context, question -> search_query\") for _ in range(2)]\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "\n",
    "        for hop in range(2):\n",
    "            search_query = self.generate_query[hop](context=context, question=question).search_query\n",
    "            passages = self.retrieve(search_query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        return self.generate_answer(context=context, question=question).copy(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = BasicMH(passages_per_hop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsp\n",
    "\n",
    "def answer_f1(example, pred, trace=None):\n",
    "    assert(type(example.answer) is str or type(example.answer) is list)\n",
    "    \n",
    "    if type(example.answer) is str:\n",
    "        return dsp.F1(pred.answer, [example.answer])\n",
    "    else: # type(example.answer) is list\n",
    "        return dsp.F1(pred.answer, example.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an evaluator on the first 300 examples of the devset.\n",
    "config = dict(num_threads=8, display_progress=True, display_table=5)\n",
    "evaluate = Evaluate(devset=devset, metric=answer_f1, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "Average Metric: 93.01237879451465 / 200  (46.5): 100%|██████████| 200/200 [02:17<00:00,  1.45it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1edb8 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1edb8 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1edb8_row0_col0, #T_1edb8_row0_col1, #T_1edb8_row0_col2, #T_1edb8_row0_col3, #T_1edb8_row0_col4, #T_1edb8_row0_col5, #T_1edb8_row0_col6, #T_1edb8_row1_col0, #T_1edb8_row1_col1, #T_1edb8_row1_col2, #T_1edb8_row1_col3, #T_1edb8_row1_col4, #T_1edb8_row1_col5, #T_1edb8_row1_col6, #T_1edb8_row2_col0, #T_1edb8_row2_col1, #T_1edb8_row2_col2, #T_1edb8_row2_col3, #T_1edb8_row2_col4, #T_1edb8_row2_col5, #T_1edb8_row2_col6, #T_1edb8_row3_col0, #T_1edb8_row3_col1, #T_1edb8_row3_col2, #T_1edb8_row3_col3, #T_1edb8_row3_col4, #T_1edb8_row3_col5, #T_1edb8_row3_col6, #T_1edb8_row4_col0, #T_1edb8_row4_col1, #T_1edb8_row4_col2, #T_1edb8_row4_col3, #T_1edb8_row4_col4, #T_1edb8_row4_col5, #T_1edb8_row4_col6 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1edb8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1edb8_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_1edb8_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_1edb8_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_1edb8_level0_col3\" class=\"col_heading level0 col3\" >rationale</th>\n",
       "      <th id=\"T_1edb8_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_1edb8_level0_col5\" class=\"col_heading level0 col5\" >context</th>\n",
       "      <th id=\"T_1edb8_level0_col6\" class=\"col_heading level0 col6\" >answer_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1edb8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1edb8_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_1edb8_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_1edb8_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_1edb8_row0_col3\" class=\"data row0 col3\" >determine the locations of Cangzhou and Qionghai. First, we know from the context that Cangzhou is a prefecture-level city in eastern Hebei province, People's Republic...</td>\n",
       "      <td id=\"T_1edb8_row0_col4\" class=\"data row0 col4\" >No, Cangzhou is in Hebei province, while Qionghai is in Hainan province.</td>\n",
       "      <td id=\"T_1edb8_row0_col5\" class=\"data row0 col5\" >['Cangzhou | \"Cangzhou Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"\"or metro\"\")...</td>\n",
       "      <td id=\"T_1edb8_row0_col6\" class=\"data row0 col6\" >✔️ [0.15384615384615385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1edb8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1edb8_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_1edb8_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_1edb8_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_1edb8_row1_col3\" class=\"data row1 col3\" >identify the organization responsible for conducting the draft. The context mentions that the 2017 NHL Expansion Draft was conducted by the National Hockey League (NHL)...</td>\n",
       "      <td id=\"T_1edb8_row1_col4\" class=\"data row1 col4\" >National Hockey League (NHL)</td>\n",
       "      <td id=\"T_1edb8_row1_col5\" class=\"data row1 col5\" >['\"Marc-André Fleury\" | \"route to a Stanley Cup championship victory, defeating the Nashville Predators in six games. The win was the third Stanley Cup of...</td>\n",
       "      <td id=\"T_1edb8_row1_col6\" class=\"data row1 col6\" >✔️ [0.8571428571428571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1edb8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1edb8_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_1edb8_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_1edb8_row2_col2\" class=\"data row2 col2\" >{'Steve Yzerman', '2006–07 Detroit Red Wings season'}</td>\n",
       "      <td id=\"T_1edb8_row2_col3\" class=\"data row2 col3\" >identify the retired professional ice hockey player who was a significant figure for the Detroit Red Wings and later became the general manager of the...</td>\n",
       "      <td id=\"T_1edb8_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_1edb8_row2_col5\" class=\"data row2 col5\" >['\"Julien BriseBois\" | \"Julien BriseBois Julien BriseBois (born January 24, 1977) is a Canadian ice hockey executive. He is the general manager for the Tampa...</td>\n",
       "      <td id=\"T_1edb8_row2_col6\" class=\"data row2 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1edb8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1edb8_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_1edb8_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_1edb8_row3_col2\" class=\"data row3 col2\" >{'Crichton Collegiate Church', 'Crichton Castle'}</td>\n",
       "      <td id=\"T_1edb8_row3_col3\" class=\"data row3 col3\" >determine the river that is near the Crichton Collegiate Church. We know that Crichton Collegiate Church is located in Midlothian, Scotland, and is situated near...</td>\n",
       "      <td id=\"T_1edb8_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
       "      <td id=\"T_1edb8_row3_col5\" class=\"data row3 col5\" >['\"Crichton Collegiate Church\" | \"Crichton Collegiate Church Crichton Collegiate Church is situated about south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself...</td>\n",
       "      <td id=\"T_1edb8_row3_col6\" class=\"data row3 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1edb8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1edb8_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_1edb8_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_1edb8_row4_col2\" class=\"data row4 col2\" >{'Ealhswith', 'Æthelweard (son of Alfred)'}</td>\n",
       "      <td id=\"T_1edb8_row4_col3\" class=\"data row4 col3\" >determine the answer. We know from the context that Æthelweard was the younger son of King Alfred the Great and Ealhswith. Since Ealhswith is mentioned...</td>\n",
       "      <td id=\"T_1edb8_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
       "      <td id=\"T_1edb8_row4_col5\" class=\"data row4 col5\" >['\"Æthelheard, king of the Hwicce\" | \"Æthelheard, king of the Hwicce Æthelheard, King of Hwicce (an Anglo Saxon kingdom in the English midlands) jointly with...</td>\n",
       "      <td id=\"T_1edb8_row4_col6\" class=\"data row4 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f98e05e6540>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 195 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "46.51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning MIPROv2 optimization process...\n",
      "\n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "These will be used for as few-shot examples candidates for our program and for creating instructions.\n",
      "\n",
      "Bootstrapping N=20 sets of demonstrations...\n",
      "Bootstrapping set 1/20\n",
      "Bootstrapping set 2/20\n",
      "Bootstrapping set 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [03:32<04:42,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 20 full traces after 44 examples in round 0.\n",
      "Bootstrapping set 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:33<05:42,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 13 full traces after 32 examples in round 0.\n",
      "Bootstrapping set 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:27<07:04,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 7 examples in round 0.\n",
      "Bootstrapping set 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:18<09:49,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n",
      "Bootstrapping set 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:06<06:16,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 16 examples in round 0.\n",
      "Bootstrapping set 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:14<07:37,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 15 examples in round 0.\n",
      "Bootstrapping set 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [03:43<04:22,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 20 full traces after 47 examples in round 0.\n",
      "Bootstrapping set 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [03:13<04:06,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 19 full traces after 45 examples in round 0.\n",
      "Bootstrapping set 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:39<06:39,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 11 full traces after 21 examples in round 0.\n",
      "Bootstrapping set 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:28<06:16,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 20 examples in round 0.\n",
      "Bootstrapping set 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [02:01<05:45,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 15 full traces after 27 examples in round 0.\n",
      "Bootstrapping set 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [03:07<04:40,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 19 full traces after 41 examples in round 0.\n",
      "Bootstrapping set 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [03:20<04:48,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 15 full traces after 42 examples in round 0.\n",
      "Bootstrapping set 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:46<06:11,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 16 full traces after 32 examples in round 0.\n",
      "Bootstrapping set 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:55<06:27,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 9 full traces after 24 examples in round 0.\n",
      "Bootstrapping set 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:33<07:25,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 8 examples in round 0.\n",
      "Bootstrapping set 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:38<06:34,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 7 full traces after 21 examples in round 0.\n",
      "Bootstrapping set 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [02:01<06:04,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 12 full traces after 26 examples in round 0.\n",
      "\n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "In this step, by default we will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "\n",
      "Proposing instructions...\n",
      "\n",
      "Proposed Instructions for Predictor 0:\n",
      "\n",
      "0: Given the fields `context`, `question`, produce the fields `search_query`.\n",
      "\n",
      "1: Propose a detailed instruction that guides the Language Model to generate a search query based on the provided context and question, ensuring clarity and relevance in the output. The instruction should encourage the model to think critically about the relationship between the context and the question before producing the search query.\n",
      "\n",
      "PROPOSED INSTRUCTION: \n",
      "\n",
      "\"Using the provided `context` and `question`, carefully analyze the relationship between the two. Your goal is to produce a `search_query` that accurately reflects the essential information needed to answer the question based on the context. Consider the key elements and themes present in the context that directly relate to the question. Formulate the search query by synthesizing this information into a concise and relevant phrase or sentence that can be used to retrieve the most pertinent information. Ensure that the search query is clear, specific, and tailored to effectively address the inquiry posed in the question.\n",
      "\n",
      "2: In a high-stakes trivia competition where every second counts, you must quickly generate a precise search query based on the provided context and question. Given the fields `context` and `question`, produce the field `search_query` that will lead to the most relevant information to answer the question effectively. Remember, your ability to formulate an accurate search query could be the difference between winning and losing!\n",
      "\n",
      "3: You are a knowledgeable trivia expert. Given the fields `context` and `question`, think critically and step by step to produce a relevant and precise `search_query` that will help in retrieving the necessary information to answer the question effectively.\n",
      "\n",
      "4: Given the provided `context` and `question`, generate a detailed `search_query` that effectively captures the essential elements needed to retrieve relevant information. Consider the specific details of the question and the context to formulate a query that addresses the inquiry accurately.\n",
      "\n",
      "5: Given the provided context and question, think critically and step by step to generate a precise and relevant search query that will help identify the specific information requested. Your search query should encapsulate the key elements of the question while being concise enough to yield effective results.\n",
      "\n",
      "6: Generate a search query based on the provided `context` and `question` that effectively captures the key elements needed to find relevant information.\n",
      "\n",
      "7: Propose a detailed instruction that guides the Language Model to generate a relevant search query based on the provided context and question. Emphasize the importance of analyzing the question thoroughly and considering the context to ensure the search query is precise and effective for retrieving accurate information. \n",
      "\n",
      "**PROPOSED INSTRUCTION:**  \n",
      "\"Analyze the provided `context` and `question` carefully. Your goal is to generate a focused and relevant `search_query` that can effectively retrieve information related to the question. Start by identifying key elements in the question that indicate what specific information is being sought. Consider the context to determine any additional relevant details that could enhance the search. Formulate a search query that includes important keywords and phrases that directly relate to the question, ensuring it is clear and concise to facilitate accurate information retrieval.\n",
      "\n",
      "8: Given the provided `context` and `question`, generate a detailed `search_query` that accurately reflects the key elements needed to retrieve relevant information. Ensure that the `search_query` captures the main topics and specific details mentioned in the `question`, while also considering the context to enhance the query's effectiveness in information retrieval.\n",
      "\n",
      "9: In a critical situation where accurate information is essential for making informed decisions, your task is to extract relevant details from the provided context and question. You must generate an effective search query that will lead to precise answers. Given the fields `context` and `question`, think carefully about the implications of your search. Your search query should encapsulate the key elements needed to retrieve the most pertinent information. Remember, the accuracy of your search could influence important outcomes.\n",
      "\n",
      "10: Propose a search query that effectively captures the essence of the provided context and question, ensuring it is tailored to retrieve relevant information. Consider the key elements of the question and the context, and think critically about how to phrase the search query to maximize the chances of finding accurate and pertinent data.\n",
      "\n",
      "11: Given the provided context and question, generate a well-reasoned search query that captures the essential elements needed to find the answer. Ensure that the search query is concise and relevant to the question being asked.\n",
      "\n",
      "12: Propose a comprehensive search query based on the provided `context` and `question`, ensuring to capture all relevant aspects of the inquiry while considering potential nuances in the phrasing of the question. Aim for specificity and clarity in the search query to enhance the retrieval of accurate and pertinent information.\n",
      "\n",
      "13: Given the provided context and question, generate a search query that encapsulates the essential elements of the inquiry, ensuring to focus on the key details that will lead to relevant information retrieval.\n",
      "\n",
      "14: You are a knowledgeable researcher tasked with identifying specific information based on a provided context and question. Given the fields `context` and `question`, produce a concise and relevant `search_query` that would effectively guide a search for the necessary information.\n",
      "\n",
      "15: In a high-stakes trivia competition where every point counts, you must quickly generate a precise search query based on the provided context and question. Your goal is to ensure that the search query is specific enough to retrieve the most relevant information to answer the question accurately. Given the fields `context` and `question`, produce the field `search_query` that will guide your information retrieval effectively.\n",
      "\n",
      "16: Propose a search query that accurately identifies crucial information to answer the following high-stakes question: Given the context, determine the impact of the subject's skills or achievements on their respective field. In your response, ensure to reason through the context and question step by step to formulate a comprehensive search query that captures the essence of the inquiry.\n",
      "\n",
      "17: Given the context and the question, generate a detailed and precise search query that captures the essence of the inquiry and facilitates effective information retrieval. Ensure the search query includes key terms and phrases that are central to the question, while reflecting the specific details provided in the context.\n",
      "\n",
      "18: You are a trivia expert tasked with generating precise search queries based on the provided context and question. Given the fields `context` and `question`, produce a relevant `search_query` that will help in retrieving accurate information to answer the question effectively.\n",
      "\n",
      "19: Generate a search query based on the provided `context` and `question` to identify relevant information that can help answer the question effectively.\n",
      "\n",
      "\n",
      "\n",
      "Proposed Instructions for Predictor 1:\n",
      "\n",
      "0: Given the fields `context`, `question`, produce the fields `search_query`.\n",
      "\n",
      "1: Given the context and question, generate a detailed search query that effectively captures the essence of the inquiry, ensuring that it is tailored to retrieve relevant information from the dataset. Include reasoning that explains the thought process behind the formulation of the search query.\n",
      "\n",
      "2: Given the provided `context` and `question`, generate a detailed `search_query` that accurately reflects the key elements and themes necessary to retrieve relevant information for answering the question effectively. Ensure that the search query captures the main subjects, relationships, and any specific details that will aid in locating the most pertinent data.\n",
      "\n",
      "3: Given the provided context and question, create a well-reasoned search query that effectively captures the relationship between the context and the question. Ensure that the search query is concise, relevant, and accurately reflects the information needed to answer the question based on the context provided.\n",
      "\n",
      "4: Given the provided context and question, generate a detailed search query that effectively captures the necessary information needed to answer the question. Ensure that the query reflects an understanding of the context and the specific inquiry, and includes relevant keywords or phrases that will facilitate accurate information retrieval.\n",
      "\n",
      "5: Given the provided context and question, generate a search query that accurately captures the necessary information needed to answer the question. Your search query should reflect the key elements of the question while considering the relevant details from the context. Ensure that the query is specific enough to yield precise results, and structure it in a way that highlights the main subjects involved.\n",
      "\n",
      "6: Given the context and question, generate a detailed search query that accurately captures the relationship between the context and the question, focusing on relevant keywords and concepts that will aid in retrieving the most pertinent information.\n",
      "\n",
      "7: Generate a detailed search query based on the provided `context` and `question`. Your response should include a clear rationale explaining the reasoning behind the search query. Focus on identifying key elements from the context that relate to the question, and formulate a search query that will effectively retrieve relevant information to answer the question accurately.\n",
      "\n",
      "8: Given the fields `context` and `question`, generate a concise and targeted `search_query` that effectively captures the essence of the question while utilizing the relevant information from the context. Ensure that the search query is framed in a way that would yield specific and accurate results when used in an information retrieval system.\n",
      "\n",
      "9: Generate a relevant search query based on the provided context and question to uncover additional information necessary for answering the inquiry.\n",
      "\n",
      "10: Given the provided `context` and `question`, generate a relevant `search_query` that will help retrieve information necessary to answer the question effectively. Ensure that the search query is specific to the topics mentioned in the context and directly addresses the inquiry posed in the question.\n",
      "\n",
      "11: Given the provided context and question, generate a focused search query that captures the essential elements needed to find the answer. Your search query should reflect a clear connection between the context and the question, highlighting key terms and relationships relevant to the inquiry.\n",
      "\n",
      "12: Given the provided `context` and `question`, generate a `search_query` that accurately captures the key elements needed to answer the question based on the context. Ensure that the search query is specific and relevant to the information sought.\n",
      "\n",
      "13: Generate a detailed search query based on the provided `context` and `question`, ensuring to consider the nuances of the question and the relevant information from the context. Your response should include a rationale explaining your thought process in determining the search query, highlighting any key elements or relationships that informed your decision.\n",
      "\n",
      "14: You are a knowledgeable trivia expert. Given the fields `context` and `question`, think critically and produce a relevant `search_query` that will help gather additional information to answer the question accurately.\n",
      "\n",
      "15: Given the provided context and question, generate an informative search query that accurately reflects the specific information needed to answer the question. Ensure that the search query is concise yet captures the essential elements from the context related to the question, facilitating effective information retrieval.\n",
      "\n",
      "16: Imagine you are an expert information retrieval specialist tasked with providing accurate and timely responses to critical inquiries in a high-stakes trivia competition. Given the fields `context` and `question`, your goal is to generate a precise `search_query` that will lead to the most relevant information. Remember, the accuracy of your search query could determine the outcome of the competition, so think carefully and strategically about the information needed to formulate your query.\n",
      "\n",
      "17: In a critical situation where accurate information is paramount, imagine you are an investigator needing to solve a case based on limited context. Given the fields `context` and `question`, generate a precise `search_query` that will lead you to the necessary information to crack the case. Your ability to formulate this search query could mean the difference between success and failure in your investigation.\n",
      "\n",
      "18: Given the provided `context` and `question`, please analyze the information and generate a `search_query` that accurately reflects the key elements needed to find relevant information. Ensure that your search query is specific, includes relevant names or terms from the context, and is formulated to retrieve data that will help answer the question effectively.\n",
      "\n",
      "19: Given the provided `context` and `question`, generate a detailed and precise `search_query` that encapsulates the necessary information to answer the question effectively. Ensure that the search query reflects the key elements identified in the context and is tailored to retrieve relevant information for answering the question.\n",
      "\n",
      "\n",
      "\n",
      "Proposed Instructions for Predictor 2:\n",
      "\n",
      "0: Given the fields `context`, `question`, produce the fields `answer`.\n",
      "\n",
      "1: Given the provided context and question, please analyze the information step by step to generate a comprehensive answer. Your response should reflect a deep understanding of the context, incorporate relevant details, and clearly address the question posed.\n",
      "\n",
      "2: Given the provided `context` and `question`, analyze the information step-by-step to generate a well-reasoned `answer` that accurately responds to the question.\n",
      "\n",
      "3: In a critical situation where accurate information is paramount, imagine you are an expert researcher tasked with providing immediate answers to urgent inquiries. Given the fields `context` and `question`, produce the fields `answer` while ensuring that your reasoning is clear and concise. Your response could impact decision-making, so approach the task with diligence and precision.\n",
      "\n",
      "4: In a high-stakes trivia competition, you are tasked with answering challenging questions based on a provided context. Your goal is to deliver accurate and well-reasoned answers to impress the judges and secure your victory. Given the fields `context` (a collection of relevant information) and `question` (the inquiry you need to answer), produce the fields `answer` (the correct response to the question). Remember, your reasoning should be clear and logical to showcase your understanding of the material.\n",
      "\n",
      "5: Imagine you are a trivia master at a high-stakes competition, where every question could lead to victory or defeat. Given the fields `context` (which contains detailed information on various topics) and `question` (a specific inquiry related to the context), your task is to quickly and accurately produce the field `answer`. Provide your reasoning step-by-step to justify your answer, ensuring clarity and precision as if you were explaining it to a live audience.\n",
      "\n",
      "6: You are a knowledgeable trivia expert. Given the fields `context` and `question`, analyze the information and provide a well-reasoned `answer`.\n",
      "\n",
      "7: Given the fields `context` and `question`, analyze the information step by step to produce a well-reasoned `answer` that accurately responds to the question based on the provided context.\n",
      "\n",
      "8: In a critical trivia competition where accurate knowledge is essential for victory, you must leverage the provided context to answer the following question. Given the fields `context` and `question`, carefully analyze the information and produce the field `answer` to help secure your team's triumph in this high-stakes challenge.\n",
      "\n",
      "9: Given the provided `context` and `question`, analyze the information step by step to produce a well-reasoned `answer` that accurately responds to the question based on the context.\n",
      "\n",
      "10: Propose a comprehensive and engaging instruction that encourages the Language Model to analyze the context carefully and provide a well-reasoned answer to the question. The instruction should emphasize the importance of logical reasoning and thorough understanding of the context to arrive at the correct answer.\n",
      "\n",
      "---\n",
      "\n",
      "PROPOSED INSTRUCTION: \"Using the provided context, carefully analyze the information to answer the question. Take a moment to think critically about the details and relationships presented in the context. Your answer should be clear and supported by logical reasoning derived from the context. Please provide both the answer and a rationale explaining how you arrived at that conclusion.\n",
      "\n",
      "11: You are an educational trivia expert. Given the fields `context` and `question`, analyze the information provided and produce the fields `answer` along with a rationale that explains your reasoning step by step.\n",
      "\n",
      "12: Given the provided `context` and `question`, analyze the information step by step to generate a well-reasoned `answer`, ensuring that you reference relevant details from the context to support your conclusion.\n",
      "\n",
      "13: Given the provided `context` and `question`, carefully analyze the information to generate a well-reasoned `answer` that directly addresses the question while utilizing relevant details from the context.\n",
      "\n",
      "14: You are an educational trivia expert. Given the fields `context` which contains relevant information and `question` that seeks specific knowledge, produce a clear and concise `answer` based on the provided information. Use logical reasoning to ensure the accuracy of your response.\n",
      "\n",
      "15: Given the provided `context` and `question`, analyze the information step by step to generate a well-reasoned `answer` that accurately addresses the question based on the context. Ensure to articulate the reasoning behind the answer clearly.\n",
      "\n",
      "16: Given the provided context and question, please analyze the information step by step to derive a well-reasoned answer. Ensure that you utilize relevant details from the context to support your conclusion and clearly articulate your reasoning process in the output. Your final response should be the definitive answer to the question posed.\n",
      "\n",
      "17: Given the provided `context` and `question`, analyze the information step by step to generate a well-reasoned `answer` that accurately responds to the inquiry based on the relevant details in the context.\n",
      "\n",
      "18: Given the provided context and question, formulate a detailed answer that not only addresses the question but also includes the reasoning behind the answer. Your response should demonstrate a clear understanding of the context and the connections between the information presented.\n",
      "\n",
      "19: You are an educational trivia expert. Given the fields `context` and `question`, analyze the information and provide a well-reasoned `answer` based on the details provided.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating the default program...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 50  (24.0): 100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n",
      "/mnt/ssd4/lm_compiler/my_env/lib/python3.12/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default program score: 24.0\n",
      "\n",
      "==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "In this step, we will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination. Bayesian Optimization will be used for this search process.\n",
      "\n",
      "== Minibatch Trial 1 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:23<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 12', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 8', 'Predictor 2: Few-Shot Set 4', 'Predictor 3: Instruction 3', 'Predictor 3: Few-Shot Set 13'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 2 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 25  (40.0): 100%|██████████| 25/25 [00:18<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 7', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 3 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 25  (12.0): 100%|██████████| 25/25 [00:17<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 12.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 17', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 2', 'Predictor 3: Few-Shot Set 16'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 4 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 25  (20.0): 100%|██████████| 25/25 [00:21<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 20.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 8', 'Predictor 2: Instruction 1', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 17', 'Predictor 3: Few-Shot Set 3'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 5 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 25  (24.0): 100%|██████████| 25/25 [00:17<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 24.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 10', 'Predictor 1: Few-Shot Set 3', 'Predictor 2: Instruction 2', 'Predictor 2: Few-Shot Set 12', 'Predictor 3: Instruction 13', 'Predictor 3: Few-Shot Set 5'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 6 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 25  (12.0): 100%|██████████| 25/25 [00:21<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 12.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 9', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 12', 'Predictor 3: Instruction 6', 'Predictor 3: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 7 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 25  (32.0): 100%|██████████| 25/25 [00:23<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 16', 'Predictor 2: Few-Shot Set 10', 'Predictor 3: Instruction 3', 'Predictor 3: Few-Shot Set 12'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 8 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 25  (24.0): 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 24.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 12', 'Predictor 1: Few-Shot Set 5', 'Predictor 2: Instruction 11', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 12', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 9 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 25  (12.0): 100%|██████████| 25/25 [00:26<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 12.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 19', 'Predictor 2: Instruction 12', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 1', 'Predictor 3: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 10 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 25  (24.0): 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 24.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 8', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 15', 'Predictor 3: Instruction 7', 'Predictor 3: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "===== Full Eval 1 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 40.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 50  (34.0): 100%|██████████| 50/50 [00:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mBest full eval score so far!\u001b[0m Score: 34.0\n",
      "=======================\n",
      "\n",
      "\n",
      "== Minibatch Trial 11 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 25  (32.0): 100%|██████████| 25/25 [00:21<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 13', 'Predictor 1: Few-Shot Set 14', 'Predictor 2: Instruction 10', 'Predictor 2: Few-Shot Set 3', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 12 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 15', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 15', 'Predictor 2: Few-Shot Set 2', 'Predictor 3: Instruction 3', 'Predictor 3: Few-Shot Set 12'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 13 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:18<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 4', 'Predictor 2: Instruction 14', 'Predictor 2: Few-Shot Set 8', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 14 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 25  (12.0): 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 12.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 7', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 6', 'Predictor 3: Instruction 19', 'Predictor 3: Few-Shot Set 12'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 15 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:27<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 15', 'Predictor 1: Few-Shot Set 7', 'Predictor 2: Instruction 13', 'Predictor 2: Few-Shot Set 11', 'Predictor 3: Instruction 15', 'Predictor 3: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 16 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:23<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 4', 'Predictor 2: Instruction 15', 'Predictor 2: Few-Shot Set 2', 'Predictor 3: Instruction 16', 'Predictor 3: Few-Shot Set 1'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 17 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 15', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 10', 'Predictor 2: Few-Shot Set 2', 'Predictor 3: Instruction 18', 'Predictor 3: Few-Shot Set 9'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 18 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:20<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 0', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 5', 'Predictor 3: Few-Shot Set 4'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 19 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 25  (24.0): 100%|██████████| 25/25 [00:22<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 24.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 13', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 10'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 20 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 10', 'Predictor 2: Instruction 9', 'Predictor 2: Few-Shot Set 1', 'Predictor 3: Instruction 9', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "===== Full Eval 2 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 36.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 15 / 50  (30.0): 100%|██████████| 50/50 [00:34<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full eval score: 30.0\n",
      "Best full eval score so far: 34.0\n",
      "=======================\n",
      "\n",
      "\n",
      "== Minibatch Trial 21 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 25  (12.0): 100%|██████████| 25/25 [00:19<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 12.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 15', 'Predictor 1: Few-Shot Set 15', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 19', 'Predictor 3: Instruction 17', 'Predictor 3: Few-Shot Set 14'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 22 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 25  (20.0): 100%|██████████| 25/25 [00:18<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 20.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 2', 'Predictor 2: Instruction 4', 'Predictor 2: Few-Shot Set 8', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 14'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 23 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 11', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 15', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 3', 'Predictor 3: Few-Shot Set 18'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 24 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 25  (32.0): 100%|██████████| 25/25 [00:24<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 5', 'Predictor 1: Few-Shot Set 8', 'Predictor 2: Instruction 14', 'Predictor 2: Few-Shot Set 8', 'Predictor 3: Instruction 15', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 25 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 11', 'Predictor 1: Few-Shot Set 7', 'Predictor 2: Instruction 14', 'Predictor 2: Few-Shot Set 15', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "===== Full Eval 3 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 36.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:38<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full eval score: 32.0\n",
      "Best full eval score so far: 34.0\n",
      "=======================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy.evaluate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, MIPROv2\n",
    "prmopt_model = dspy.OpenAI(model='gpt-4o-mini', max_tokens=1000)\n",
    "dspy.settings.configure(lm=prmopt_model)\n",
    "bootstrap_optimizer = MIPROv2(\n",
    "    prompt_model=prmopt_model,\n",
    "    metric=dspy.evaluate.answer_exact_match,\n",
    "    num_candidates=10,\n",
    "    num_threads=8,\n",
    ")\n",
    "optimized_matplot = bootstrap_optimizer.compile(\n",
    "    agent,\n",
    "    trainset=trainset,\n",
    "    max_bootstrapped_demos=20,\n",
    "    max_labeled_demos=4,\n",
    "    num_trials=25,\n",
    "    valset=valset,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.734819420345733 / 50  (59.5): 100%|██████████| 50/50 [00:36<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_193ab th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_193ab td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_193ab_row0_col0, #T_193ab_row0_col1, #T_193ab_row0_col2, #T_193ab_row0_col3, #T_193ab_row0_col4, #T_193ab_row0_col5, #T_193ab_row0_col6, #T_193ab_row1_col0, #T_193ab_row1_col1, #T_193ab_row1_col2, #T_193ab_row1_col3, #T_193ab_row1_col4, #T_193ab_row1_col5, #T_193ab_row1_col6, #T_193ab_row2_col0, #T_193ab_row2_col1, #T_193ab_row2_col2, #T_193ab_row2_col3, #T_193ab_row2_col4, #T_193ab_row2_col5, #T_193ab_row2_col6, #T_193ab_row3_col0, #T_193ab_row3_col1, #T_193ab_row3_col2, #T_193ab_row3_col3, #T_193ab_row3_col4, #T_193ab_row3_col5, #T_193ab_row3_col6, #T_193ab_row4_col0, #T_193ab_row4_col1, #T_193ab_row4_col2, #T_193ab_row4_col3, #T_193ab_row4_col4, #T_193ab_row4_col5, #T_193ab_row4_col6 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_193ab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_193ab_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_193ab_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_193ab_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_193ab_level0_col3\" class=\"col_heading level0 col3\" >rationale</th>\n",
       "      <th id=\"T_193ab_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_193ab_level0_col5\" class=\"col_heading level0 col5\" >context</th>\n",
       "      <th id=\"T_193ab_level0_col6\" class=\"col_heading level0 col6\" >answer_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_193ab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_193ab_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_193ab_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_193ab_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_193ab_row0_col3\" class=\"data row0 col3\" >determine whether both Cangzhou and Qionghai are located in the Hebei province of China. First, we analyze the context provided for Cangzhou. The text states...</td>\n",
       "      <td id=\"T_193ab_row0_col4\" class=\"data row0 col4\" >no</td>\n",
       "      <td id=\"T_193ab_row0_col5\" class=\"data row0 col5\" >['Cangzhou | \"Cangzhou Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"\"or metro\"\")...</td>\n",
       "      <td id=\"T_193ab_row0_col6\" class=\"data row0 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_193ab_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_193ab_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_193ab_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_193ab_row1_col2\" class=\"data row1 col2\" >{'2017–18 Pittsburgh Penguins season', '2017 NHL Expansion Draft'}</td>\n",
       "      <td id=\"T_193ab_row1_col3\" class=\"data row1 col3\" >determine who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights. The context mentions the \"2017 NHL Expansion Draft,\" which...</td>\n",
       "      <td id=\"T_193ab_row1_col4\" class=\"data row1 col4\" >National Hockey League (NHL)</td>\n",
       "      <td id=\"T_193ab_row1_col5\" class=\"data row1 col5\" >['\"Marc-André Fleury\" | \"route to a Stanley Cup championship victory, defeating the Nashville Predators in six games. The win was the third Stanley Cup of...</td>\n",
       "      <td id=\"T_193ab_row1_col6\" class=\"data row1 col6\" >✔️ [0.8571428571428571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_193ab_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_193ab_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_193ab_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_193ab_row2_col2\" class=\"data row2 col2\" >{'2006–07 Detroit Red Wings season', 'Steve Yzerman'}</td>\n",
       "      <td id=\"T_193ab_row2_col3\" class=\"data row2 col3\" >determine the answer to the question. The context mentions Steve Yzerman, who is a Canadian retired professional ice hockey player and the current general manager...</td>\n",
       "      <td id=\"T_193ab_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_193ab_row2_col5\" class=\"data row2 col5\" >['\"2010–11 Tampa Bay Lightning season\" | \"2010–11 Tampa Bay Lightning season The 2010–11 Tampa Bay Lightning season was the 19th season for the Lightning franchise...</td>\n",
       "      <td id=\"T_193ab_row2_col6\" class=\"data row2 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_193ab_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_193ab_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_193ab_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_193ab_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_193ab_row3_col3\" class=\"data row3 col3\" >determine the answer to the question about the river near Crichton Collegiate Church. The context provided does not mention any specific river associated with the...</td>\n",
       "      <td id=\"T_193ab_row3_col4\" class=\"data row3 col4\" >The context does not provide information about a river near Crichton Collegiate Church.</td>\n",
       "      <td id=\"T_193ab_row3_col5\" class=\"data row3 col5\" >['\"Crichton Collegiate Church\" | \"Crichton Collegiate Church Crichton Collegiate Church is situated about south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself...</td>\n",
       "      <td id=\"T_193ab_row3_col6\" class=\"data row3 col6\" >✔️ [0.15384615384615385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_193ab_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_193ab_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_193ab_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_193ab_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
       "      <td id=\"T_193ab_row4_col3\" class=\"data row4 col3\" >determine the answer to the question regarding Ealhswith's son Æthelweard. The context provided mentions that Æthelweard was the younger son of King Alfred the Great...</td>\n",
       "      <td id=\"T_193ab_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
       "      <td id=\"T_193ab_row4_col5\" class=\"data row4 col5\" >['\"Æthelheard, king of the Hwicce\" | \"Æthelheard, king of the Hwicce Æthelheard, King of Hwicce (an Anglo Saxon kingdom in the English midlands) jointly with...</td>\n",
       "      <td id=\"T_193ab_row4_col6\" class=\"data row4 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd222a54320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "59.47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_matplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('retrieve', <dspy.retrieve.retrieve.Retrieve object at 0x7fd1fdbc2030>), ('generate_query[0]', Predict(StringSignature(context, question -> rationale, search_query\n",
      "    instructions='Given the fields `context`, `question`, produce the fields `search_query`.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the search_query}. We ...', '__dspy_field_type': 'output'})\n",
      "    search_query = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Search Query:', 'desc': '${search_query}'})\n",
      "))), ('generate_query[1]', Predict(StringSignature(context, question -> rationale, search_query\n",
      "    instructions='Given the fields `context`, `question`, produce the fields `search_query`.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the search_query}. We ...', '__dspy_field_type': 'output'})\n",
      "    search_query = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Search Query:', 'desc': '${search_query}'})\n",
      "))), ('generate_answer', Predict(StringSignature(context, question -> rationale, answer\n",
      "    instructions='Given the fields `context`, `question`, produce the fields `answer`.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
      ")))]\n"
     ]
    }
   ],
   "source": [
    "optimized_matplot.save('optimized_qa.dspy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load('optimized_qa.dspy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112.32022976163844 / 200  (56.2): 100%|██████████| 200/200 [02:33<00:00,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_99b50 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_99b50 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_99b50_row0_col0, #T_99b50_row0_col1, #T_99b50_row0_col2, #T_99b50_row0_col3, #T_99b50_row0_col4, #T_99b50_row0_col5, #T_99b50_row0_col6, #T_99b50_row1_col0, #T_99b50_row1_col1, #T_99b50_row1_col2, #T_99b50_row1_col3, #T_99b50_row1_col4, #T_99b50_row1_col5, #T_99b50_row1_col6, #T_99b50_row2_col0, #T_99b50_row2_col1, #T_99b50_row2_col2, #T_99b50_row2_col3, #T_99b50_row2_col4, #T_99b50_row2_col5, #T_99b50_row2_col6, #T_99b50_row3_col0, #T_99b50_row3_col1, #T_99b50_row3_col2, #T_99b50_row3_col3, #T_99b50_row3_col4, #T_99b50_row3_col5, #T_99b50_row3_col6, #T_99b50_row4_col0, #T_99b50_row4_col1, #T_99b50_row4_col2, #T_99b50_row4_col3, #T_99b50_row4_col4, #T_99b50_row4_col5, #T_99b50_row4_col6 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_99b50\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_99b50_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_99b50_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_99b50_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_99b50_level0_col3\" class=\"col_heading level0 col3\" >rationale</th>\n",
       "      <th id=\"T_99b50_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_99b50_level0_col5\" class=\"col_heading level0 col5\" >context</th>\n",
       "      <th id=\"T_99b50_level0_col6\" class=\"col_heading level0 col6\" >answer_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_99b50_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_99b50_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_99b50_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_99b50_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_99b50_row0_col3\" class=\"data row0 col3\" >determine whether both Cangzhou and Qionghai are located in the Hebei province of China. First, we analyze the context provided for Cangzhou. The text states...</td>\n",
       "      <td id=\"T_99b50_row0_col4\" class=\"data row0 col4\" >no</td>\n",
       "      <td id=\"T_99b50_row0_col5\" class=\"data row0 col5\" >['Cangzhou | \"Cangzhou Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"\"or metro\"\")...</td>\n",
       "      <td id=\"T_99b50_row0_col6\" class=\"data row0 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99b50_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_99b50_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_99b50_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_99b50_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_99b50_row1_col3\" class=\"data row1 col3\" >determine who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights. The context mentions the \"2017 NHL Expansion Draft,\" which...</td>\n",
       "      <td id=\"T_99b50_row1_col4\" class=\"data row1 col4\" >NHL</td>\n",
       "      <td id=\"T_99b50_row1_col5\" class=\"data row1 col5\" >['\"Marc-André Fleury\" | \"route to a Stanley Cup championship victory, defeating the Nashville Predators in six games. The win was the third Stanley Cup of...</td>\n",
       "      <td id=\"T_99b50_row1_col6\" class=\"data row1 col6\" ><class 'str'></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99b50_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_99b50_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_99b50_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_99b50_row2_col2\" class=\"data row2 col2\" >{'Steve Yzerman', '2006–07 Detroit Red Wings season'}</td>\n",
       "      <td id=\"T_99b50_row2_col3\" class=\"data row2 col3\" >determine the answer to the question. The context mentions Steve Yzerman, who is a Canadian retired professional ice hockey player and the current general manager...</td>\n",
       "      <td id=\"T_99b50_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_99b50_row2_col5\" class=\"data row2 col5\" >['\"2010–11 Tampa Bay Lightning season\" | \"2010–11 Tampa Bay Lightning season The 2010–11 Tampa Bay Lightning season was the 19th season for the Lightning franchise...</td>\n",
       "      <td id=\"T_99b50_row2_col6\" class=\"data row2 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99b50_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_99b50_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_99b50_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_99b50_row3_col2\" class=\"data row3 col2\" >{'Crichton Collegiate Church', 'Crichton Castle'}</td>\n",
       "      <td id=\"T_99b50_row3_col3\" class=\"data row3 col3\" >determine the answer to the question regarding the river near Crichton Collegiate Church. The context provided does not mention any specific river associated with the...</td>\n",
       "      <td id=\"T_99b50_row3_col4\" class=\"data row3 col4\" >The context does not provide information about a river near Crichton Collegiate Church.</td>\n",
       "      <td id=\"T_99b50_row3_col5\" class=\"data row3 col5\" >['\"Crichton Collegiate Church\" | \"Crichton Collegiate Church Crichton Collegiate Church is situated about south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself...</td>\n",
       "      <td id=\"T_99b50_row3_col6\" class=\"data row3 col6\" >✔️ [0.15384615384615385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99b50_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_99b50_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_99b50_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_99b50_row4_col2\" class=\"data row4 col2\" >{'Ealhswith', 'Æthelweard (son of Alfred)'}</td>\n",
       "      <td id=\"T_99b50_row4_col3\" class=\"data row4 col3\" >determine the answer to the question regarding Ealhswith's son Æthelweard. The context provides information about Æthelweard, stating that he was the younger son of King...</td>\n",
       "      <td id=\"T_99b50_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
       "      <td id=\"T_99b50_row4_col5\" class=\"data row4 col5\" >['\"Æthelheard, king of the Hwicce\" | \"Æthelheard, king of the Hwicce Æthelheard, King of Hwicce (an Anglo Saxon kingdom in the English midlands) jointly with...</td>\n",
       "      <td id=\"T_99b50_row4_col6\" class=\"data row4 col6\" >✔️ [1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f98e2737c80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 195 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, outputs = evaluate(agent, return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(d1, d2) -> dict:\n",
    "    merged = {}\n",
    "    for k, v in d1.items():\n",
    "        if k in d2:\n",
    "            merged[f\"example_{k}\"] = v\n",
    "        else:\n",
    "            merged[k] = v\n",
    "\n",
    "    for k, v in d2.items():\n",
    "        if k in d1:\n",
    "            merged[f\"pred_{k}\"] = v\n",
    "        else:\n",
    "            merged[k] = v\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    merge_dicts(example, prediction) | {\"correct\": score} for example, prediction, score in outputs \n",
    "]\n",
    "result_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('qa_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='determine if both \"Walt Disney\" and \"Sacro GRA\" are documentary films. First, we analyze the context for \"Sacro GRA,\" which is described as a documentary film directed by Gianfranco Rosi that won the Golden Lion at the Venice Film Festival. This confirms that \"Sacro GRA\" is indeed a documentary. Next, we look at the context for \"Walt Disney,\" which is also identified as a documentary film created by PBS for the \"American Experience\" program, focusing on the life and legacy of Walt Disney. Since both films are explicitly categorized as documentaries in their respective contexts, we can conclude that the answer to the question is yes.',\n",
       "    answer='yes',\n",
       "    context=['\"Sacro GRA\" | \"Sacro GRA Sacro GRA (, Italian for \"\"Holy GRA\"\") is a 2013 Italian documentary film directed by Gianfranco Rosi. It won the Golden Lion at the 70th Venice International Film Festival. It was the first documentary film to win the award at the Venice Festival. The film depicts life along the Grande Raccordo Anulare, the ring-road highway that circles Rome. Rosi spent over two years in filming, while the film\\'s editing required eight months of work. According to the director, the film was inspired by Italo Calvino\\'s novel \"\"Invisible Cities\"\" (1972), in which the explorer Marco Polo is imagined describing\"', '\"Sacro GRA\" | \"his travels to the Emperor of China Kublai Khan. Sacro GRA Sacro GRA (, Italian for \"\"Holy GRA\"\") is a 2013 Italian documentary film directed by Gianfranco Rosi. It won the Golden Lion at the 70th Venice International Film Festival. It was the first documentary film to win the award at the Venice Festival. The film depicts life along the Grande Raccordo Anulare, the ring-road highway that circles Rome. Rosi spent over two years in filming, while the film\\'s editing required eight months of work. According to the director, the film was inspired by Italo Calvino\\'s novel \"\"Invisible Cities\"\" (1972),\"', '\"Walt Disney (film)\" | \"Walt Disney (film) Walt Disney is a documentary film created by PBS for the \"\"American Experience\"\" program. The two-part, four-hour documentary premiered on September 14, 2015 and centers on the life, times and legacy of Walt Disney. According to Sarah Colt, director of the documentary film, the biggest challenge was \"\"capturing the truth of the man who had such [an] outsized influence and notoriety ... People think they know him but in reality they don\\'t know him ... He was a human being with many layers of complexity.\"\" Rob Lowman, of the \"\"Los Angeles Daily News\"\", described \"\"Disneyesque\"\" as being\"', '\"Walt Disney (film)\" | \"The Triumph of the American Imagination\"\"” (2006), notes that “the film takes the measure of [Walt Disney] as a human being.\"\" Walt Disney (film) Walt Disney is a documentary film created by PBS for the \"\"American Experience\"\" program. The two-part, four-hour documentary premiered on September 14, 2015 and centers on the life, times and legacy of Walt Disney. According to Sarah Colt, director of the documentary film, the biggest challenge was \"\"capturing the truth of the man who had such [an] outsized influence and notoriety ... People think they know him but in reality they don\\'t know him ... He\"']\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(question=\"Are Walt Disney and Sacro GRA both documentry films?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
