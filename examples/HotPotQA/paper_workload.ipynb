{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd4/lm_compiler/my_env/lib/python3.12/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/mnt/ssd4/lm_compiler/my_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from compiler.utils import load_api_key\n",
    "\n",
    "load_api_key('/mnt/ssd4/lm_compiler/secrets.toml')\n",
    "\n",
    "gpt4o_mini = dspy.OpenAI('gpt-4o-mini', max_tokens=1000)\n",
    "colbert = dspy.ColBERTv2(url='http://192.168.1.18:8893/api/search')\n",
    "dspy.configure(lm=gpt4o_mini, rm=colbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = HotPotQA(train_seed=1, train_size=200, eval_seed=2023, dev_size=50, test_size=0)\n",
    "trainset = [x.with_inputs('question') for x in dataset.train[0:150]]\n",
    "valset = [x.with_inputs('question') for x in dataset.train[150:200]]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "# show an example datapoint; it's just a question-answer pair\n",
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "class BasicMH(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_query = [dspy.ChainOfThought(\"context, question -> search_query\") for _ in range(2)]\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "\n",
    "        for hop in range(2):\n",
    "            search_query = self.generate_query[hop](context=context, question=question).search_query\n",
    "            passages = self.retrieve(search_query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        return self.generate_answer(context=context, question=question).copy(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = BasicMH(passages_per_hop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:00<00:00, 103.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dcf39 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dcf39 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dcf39_row0_col0, #T_dcf39_row0_col1, #T_dcf39_row0_col2, #T_dcf39_row0_col3, #T_dcf39_row0_col4, #T_dcf39_row0_col5, #T_dcf39_row0_col6, #T_dcf39_row1_col0, #T_dcf39_row1_col1, #T_dcf39_row1_col2, #T_dcf39_row1_col3, #T_dcf39_row1_col4, #T_dcf39_row1_col5, #T_dcf39_row1_col6, #T_dcf39_row2_col0, #T_dcf39_row2_col1, #T_dcf39_row2_col2, #T_dcf39_row2_col3, #T_dcf39_row2_col4, #T_dcf39_row2_col5, #T_dcf39_row2_col6, #T_dcf39_row3_col0, #T_dcf39_row3_col1, #T_dcf39_row3_col2, #T_dcf39_row3_col3, #T_dcf39_row3_col4, #T_dcf39_row3_col5, #T_dcf39_row3_col6, #T_dcf39_row4_col0, #T_dcf39_row4_col1, #T_dcf39_row4_col2, #T_dcf39_row4_col3, #T_dcf39_row4_col4, #T_dcf39_row4_col5, #T_dcf39_row4_col6 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dcf39\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dcf39_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_dcf39_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_dcf39_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_dcf39_level0_col3\" class=\"col_heading level0 col3\" >rationale</th>\n",
       "      <th id=\"T_dcf39_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_dcf39_level0_col5\" class=\"col_heading level0 col5\" >context</th>\n",
       "      <th id=\"T_dcf39_level0_col6\" class=\"col_heading level0 col6\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dcf39_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dcf39_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_dcf39_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_dcf39_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_dcf39_row0_col3\" class=\"data row0 col3\" >determine the locations of Cangzhou and Qionghai. Cangzhou is explicitly stated to be in eastern Hebei province, while Qionghai is identified as a county-level city...</td>\n",
       "      <td id=\"T_dcf39_row0_col4\" class=\"data row0 col4\" >No, Cangzhou is in Hebei province, while Qionghai is in Hainan province.</td>\n",
       "      <td id=\"T_dcf39_row0_col5\" class=\"data row0 col5\" >['Cangzhou | \"Cangzhou Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"\"or metro\"\")...</td>\n",
       "      <td id=\"T_dcf39_row0_col6\" class=\"data row0 col6\" ><class 'str'></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcf39_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dcf39_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_dcf39_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_dcf39_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_dcf39_row1_col3\" class=\"data row1 col3\" >identify the organization responsible for conducting the draft. The context mentions that the 2017 NHL Expansion Draft was conducted by the National Hockey League (NHL)...</td>\n",
       "      <td id=\"T_dcf39_row1_col4\" class=\"data row1 col4\" >The National Hockey League (NHL) conducts the draft.</td>\n",
       "      <td id=\"T_dcf39_row1_col5\" class=\"data row1 col5\" >['\"Marc-André Fleury\" | \"route to a Stanley Cup championship victory, defeating the Nashville Predators in six games. The win was the third Stanley Cup of...</td>\n",
       "      <td id=\"T_dcf39_row1_col6\" class=\"data row1 col6\" ><class 'str'></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcf39_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dcf39_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_dcf39_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_dcf39_row2_col2\" class=\"data row2 col2\" >{'2006–07 Detroit Red Wings season', 'Steve Yzerman'}</td>\n",
       "      <td id=\"T_dcf39_row2_col3\" class=\"data row2 col3\" >identify the retired professional ice hockey player mentioned in the context. We know that the question refers to a significant event in the history of...</td>\n",
       "      <td id=\"T_dcf39_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_dcf39_row2_col5\" class=\"data row2 col5\" >['\"Julien BriseBois\" | \"Julien BriseBois Julien BriseBois (born January 24, 1977) is a Canadian ice hockey executive. He is the general manager for the Tampa...</td>\n",
       "      <td id=\"T_dcf39_row2_col6\" class=\"data row2 col6\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcf39_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dcf39_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_dcf39_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_dcf39_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_dcf39_row3_col3\" class=\"data row3 col3\" >determine the river near the Crichton Collegiate Church. We know that Crichton Collegiate Church is located in Midlothian, Scotland, and from the context provided, we...</td>\n",
       "      <td id=\"T_dcf39_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
       "      <td id=\"T_dcf39_row3_col5\" class=\"data row3 col5\" >['\"Crichton Collegiate Church\" | \"Crichton Collegiate Church Crichton Collegiate Church is situated about south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself...</td>\n",
       "      <td id=\"T_dcf39_row3_col6\" class=\"data row3 col6\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcf39_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_dcf39_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_dcf39_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_dcf39_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
       "      <td id=\"T_dcf39_row4_col3\" class=\"data row4 col3\" >determine the answer. We know from the context that Æthelweard was the younger son of King Alfred the Great and Ealhswith. Since the question specifically...</td>\n",
       "      <td id=\"T_dcf39_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
       "      <td id=\"T_dcf39_row4_col5\" class=\"data row4 col5\" >['\"Æthelweard (son of Alfred)\" | \"Æthelweard (son of Alfred) Æthelweard (d. 920 or 922) was the younger son of King Alfred the Great and Ealhswith....</td>\n",
       "      <td id=\"T_dcf39_row4_col6\" class=\"data row4 col6\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7cc271b7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up an evaluator on the first 300 examples of the devset.\n",
    "config = dict(num_threads=8, display_progress=True, display_table=5)\n",
    "evaluate = Evaluate(devset=devset, metric=dspy.evaluate.answer_exact_match, **config)\n",
    "\n",
    "evaluate(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning MIPROv2 optimization process...\n",
      "\n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "These will be used for as few-shot examples candidates for our program and for creating instructions.\n",
      "\n",
      "Bootstrapping N=20 sets of demonstrations...\n",
      "Bootstrapping set 1/20\n",
      "Bootstrapping set 2/20\n",
      "Bootstrapping set 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:42<14:28,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n",
      "Bootstrapping set 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:25<15:32,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples in round 0.\n",
      "Bootstrapping set 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:16<13:43,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n",
      "Bootstrapping set 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:06<08:32,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n",
      "Bootstrapping set 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:05<14:29,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n",
      "Bootstrapping set 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:20<12:40,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n",
      "Bootstrapping set 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:10<13:22,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples in round 0.\n",
      "Bootstrapping set 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:21<13:19,  5.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n",
      "Bootstrapping set 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:34<11:52,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n",
      "Bootstrapping set 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:04<05:19,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n",
      "Bootstrapping set 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:20<12:18,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples in round 0.\n",
      "Bootstrapping set 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:13<11:20,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n",
      "Bootstrapping set 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:19<16:19,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n",
      "Bootstrapping set 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:22<10:41,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n",
      "Bootstrapping set 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:19<09:24,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n",
      "Bootstrapping set 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:20<12:46,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n",
      "Bootstrapping set 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:17<10:55,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n",
      "Bootstrapping set 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:28<11:29,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 7 examples in round 0.\n",
      "\n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "In this step, by default we will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "\n",
      "Proposing instructions...\n",
      "\n",
      "Proposed Instructions for Predictor 0:\n",
      "\n",
      "0: Given the fields `context`, `question`, produce the fields `search_query`.\n",
      "\n",
      "1: Given the provided context and a specific question, explain the reasoning behind your thought process step-by-step to generate a relevant search query that will help in retrieving information to answer the question effectively. Focus on how the context informs the search query, and ensure clarity in your explanation to facilitate understanding of your reasoning.\n",
      "\n",
      "2: Imagine you are a renowned pop culture expert tasked with answering critical questions for a live trivia competition. Your reputation is on the line as you need to quickly and accurately identify relevant information. Given the fields `context` (which may be empty or contain hints from previous questions) and `question`, generate a precise `search_query` that will help you find the necessary information to answer the question effectively. Remember, the accuracy of your response could determine your success in the competition!\n",
      "\n",
      "3: You are an information retrieval expert. Given the fields `context` and `question`, generate a concise and relevant `search_query` that accurately captures the essence of the question while considering the context provided.\n",
      "\n",
      "4: Generate a search query that identifies the locations of the entities mentioned in the question based on the provided context. Ensure the query is structured to retrieve information that confirms whether both entities are located in the same geographic region.\n",
      "\n",
      "5: Given the provided `context` and `question`, analyze the geographical and contextual relationships to generate a relevant `search_query` that will effectively retrieve information related to the question. Use logical reasoning to ensure the query captures the necessary connections between the entities involved.\n",
      "\n",
      "6: Generate a detailed search query based on the provided context and question that identifies key entities and relationships relevant to the inquiry.\n",
      "\n",
      "7: Given the fields `context` (which contains any relevant background information) and `question` (the user's query regarding a specific topic), your task is to generate a detailed `search_query` that will effectively retrieve pertinent information. Consider the context provided and analyze the question to identify key entities and relationships. Your search query should be concise yet comprehensive enough to capture the necessary details for accurate information retrieval.\n",
      "\n",
      "8: Given the context and the question, think critically and provide a well-structured search query that will help retrieve relevant information for answering the question. Make sure to consider the key elements of the question and any specific terms that will enhance the search effectiveness.\n",
      "\n",
      "9: In a high-stakes trivia competition where every second counts, you are tasked with answering a challenging question about a prominent basketball player. Given the fields `context` and `question`, generate a precise and effective `search_query` that will help you quickly retrieve the necessary information to correctly answer the question. Your response should demonstrate clear reasoning and ensure that the search query is focused on identifying the relevant details needed to succeed in this competitive environment.\n",
      "\n",
      "10: Given the context and question, analyze the information to formulate a precise search query that captures the essence of the inquiry while considering any relevant details from the context. Your search query should be concise yet comprehensive enough to guide the retrieval of pertinent information.\n",
      "\n",
      "11: Given the provided context and question, generate a clear and concise search query that identifies relevant movies based on the specified literary works. Include a step-by-step reasoning process to explain how the search query is derived from the context and question.\n",
      "\n",
      "12: Using the provided `context` and `question`, craft a detailed and precise `search_query` that captures the essence of the question. Consider the key elements and relationships within the question to ensure that the search query effectively targets the relevant information needed to answer it.\n",
      "\n",
      "13: Given the provided context and question, generate a comprehensive search query that will help retrieve relevant information to answer the question effectively. Ensure that the search query includes key terms from the question and considers the context to enhance the relevance of the retrieved data.\n",
      "\n",
      "14: You are a knowledgeable sports historian. Given the fields `context` and `question`, produce a concise and relevant `search_query` that will help retrieve information to accurately answer the question.\n",
      "\n",
      "15: Imagine you are a trivia master in a high-stakes competition where your knowledge will determine the winner. Given the fields `context` and `question`, generate an accurate and precise `search_query` that will help you quickly retrieve the necessary information to answer the question correctly. Your ability to formulate this search query could be the difference between victory and defeat!\n",
      "\n",
      "16: In a scenario where you are tasked with answering critical questions for an important academic panel discussing the influence of literature on American culture, you must generate precise search queries based on the provided context and question. Your goal is to ensure that the panel receives accurate and insightful information that can influence their decisions and discussions. \n",
      "\n",
      "Given the fields `context` and `question`, produce the fields `search_query` that will lead to comprehensive and relevant information retrieval.\n",
      "\n",
      "17: Propose a detailed instruction that encourages the language model to think critically and creatively about the context and question at hand, ensuring that it generates a comprehensive search query that will yield relevant information.\n",
      "\n",
      "---\n",
      "\n",
      "**PROPOSED INSTRUCTION:** Given the provided `context` and `question`, please analyze the information critically and creatively. Your task is to produce a `search_query` that effectively captures the essence of the question while considering the context. Think about the specific details needed to answer the question accurately and formulate a search query that encompasses all relevant aspects.\n",
      "\n",
      "18: You are a knowledgeable trivia expert specializing in pop culture. Given the fields `context` and `question`, produce a well-reasoned `search_query` that captures the essence of the question while reflecting on relevant details from the context.\n",
      "\n",
      "19: Given the provided `context` and `question`, analyze the information step by step to generate a relevant `search_query` that identifies key entities and relationships pertinent to the inquiry.\n",
      "\n",
      "\n",
      "\n",
      "Proposed Instructions for Predictor 1:\n",
      "\n",
      "0: Given the fields `context`, `question`, produce the fields `search_query`.\n",
      "\n",
      "1: Given the fields `context` and `question`, please analyze the information and generate a concise and relevant `search_query` that captures the key elements needed to retrieve additional information related to the question. Ensure that the search query is specific enough to yield useful results while being broad enough to encompass various aspects of the topic.\n",
      "\n",
      "2: Given the provided context and question, analyze the information step by step to generate a precise search query that effectively captures the relationship between the entities mentioned. Your goal is to create a search query that clearly reflects the essence of the question based on the context provided.\n",
      "\n",
      "3: Given the provided context and question, generate a concise and relevant search query that identifies key elements necessary to answer the question effectively. Ensure that the search query reflects the specific information sought based on the context provided and is structured to facilitate accurate information retrieval.\n",
      "\n",
      "4: Given the provided context and question, generate a detailed search query that confirms the locations of the cathedrals mentioned in the question. Ensure to extract relevant information from the context to substantiate the query and support accurate reasoning in your response.\n",
      "\n",
      "5: Given the provided context and question, generate a detailed search query that identifies key geographical relationships and associations. Consider the information in the context to extract relevant entities and their connections, ensuring the query reflects the specific relationship being asked about in the question. Aim for clarity and conciseness in the search query, focusing on the main elements that will lead to an accurate answer.\n",
      "\n",
      "6: Given the provided context and question, formulate a precise and effective search query that identifies the relevant information needed to answer the question. Ensure that the search query targets the specific actress mentioned in the context and confirms her involvement in the film \"The Shore,\" while also highlighting her record as the youngest actress to portray Ophelia in a Royal Shakespeare Company production.\n",
      "\n",
      "7: Given the provided context and question, create a detailed search query that accurately reflects the information needed to answer the question. Your search query should focus on identifying the origin of the singer associated with the specific song mentioned in the question. Use the context to inform your query, ensuring it is relevant and specific to the entities discussed.\n",
      "\n",
      "8: Given the fields `context` and `question`, provide a detailed reasoning process to generate a relevant `search_query` that captures the essential information needed to answer the question. Ensure that the search query is specific and directly related to the context provided, reflecting a clear understanding of the relationships and entities involved.\n",
      "\n",
      "9: Given the provided context and question, generate a search query that accurately identifies the college team associated with the professional basketball player mentioned in the context. Focus on extracting key details from the context to formulate a relevant and precise search query.\n",
      "\n",
      "10: Generate a focused search query based on the provided `context` and `question` that will help retrieve relevant information to answer the question.\n",
      "\n",
      "11: Given the provided `context` and `question`, analyze the information to produce a relevant `search_query` that accurately reflects the inquiry. Consider the relationships between the entities mentioned and the underlying themes in the context to formulate a precise and effective search query.\n",
      "\n",
      "12: Given the provided `context` and `question`, generate a relevant `search_query` that accurately reflects the information needed to answer the question based on the context. Ensure that the search query is specific and focused on the entities or concepts mentioned in the question.\n",
      "\n",
      "13: Given the provided context and question, generate a comprehensive search query that will enable the retrieval of relevant information necessary to answer the question. Ensure that the search query reflects the need to compare the publication dates of the specified entities, utilizing deductive reasoning based on the context provided.\n",
      "\n",
      "14: You are an information retrieval expert. Given the fields `context` and `question`, analyze the information and produce a relevant `search_query` that will help in finding the answer to the question. Make sure to explain your reasoning step by step for clarity.\n",
      "\n",
      "15: Based on the provided information, here’s a proposed instruction:\n",
      "\n",
      "---\n",
      "\n",
      "PROPOSED INSTRUCTION: Given the provided `context` and `question`, carefully analyze the relevant information and reasoning to formulate a precise `search_query`. Ensure that the search query captures the essential elements necessary to retrieve information that directly addresses the question, taking into account the specific details and relationships outlined in the context.\n",
      "\n",
      "16: ** In a high-stakes trivia competition where every answer matters, you must quickly determine the relevance of the provided context to the question asked. Given the fields `context` and `question`, generate a concise and effective `search_query` that will help you retrieve the most pertinent information to answer the question accurately. Remember, the accuracy of your search query could determine whether your team wins or loses the game!\n",
      "\n",
      "17: Imagine you are a renowned film historian tasked with resolving a heated debate among movie enthusiasts about the release dates of two films: 'The Tree' (2010) and 'Pond Hockey.' To settle this argument, you must carefully analyze the provided context and formulate a precise search query that will uncover the necessary release dates of both films. Given the fields `context` and `question`, generate a search query that will help you find the release dates of 'The Tree' and 'Pond Hockey' to definitively determine which film was created first.\n",
      "\n",
      "18: Given the provided context and question, create a detailed search query that accurately reflects the main focus of the question while utilizing the relevant information from the context. Ensure that the search query is clear, specific, and directed towards retrieving information about the original launch location of the Angry Birds game.\n",
      "\n",
      "19: Given the provided `context` and `question`, analyze the information to identify key details that will help you formulate a precise `search_query`. Ensure that the search query encapsulates the essence of the question while drawing from the relevant context provided.\n",
      "\n",
      "\n",
      "\n",
      "Proposed Instructions for Predictor 2:\n",
      "\n",
      "0: Given the fields `context`, `question`, produce the fields `answer`.\n",
      "\n",
      "1: Propose a comprehensive instruction that guides the Language Model to analyze the provided context and question, systematically break down the reasoning process, and generate a well-informed answer. Ensure that the instruction emphasizes the importance of clarity, accuracy, and relevance in the response.\n",
      "\n",
      "---\n",
      "\n",
      "PROPOSED INSTRUCTION: \"Analyze the provided context and the question carefully. Step by step, reason through the information in the context to identify relevant details that directly address the question. After considering all pertinent aspects, generate a clear and concise answer that accurately reflects the information derived from the context. Be sure to justify your reasoning process to enhance the transparency of how you arrived at your answer.\n",
      "\n",
      "2: Given the provided `context` and `question`, analyze the information step by step to produce a well-reasoned `answer`. Ensure that the answer is derived from the context and directly addresses the question asked.\n",
      "\n",
      "3: In a high-stakes trivia competition where every second counts, you are tasked with answering questions based on provided contexts. Your goal is to provide accurate answers quickly to help your team win. Given the fields `context` and `question`, produce a clear and concise `answer` that reflects your understanding of the material. Remember, the accuracy of your response could determine the outcome of the competition!\n",
      "\n",
      "4: In a high-stakes trivia competition where every point counts, you are tasked with answering a critical question based on the provided context. Your goal is to determine whether both cathedrals mentioned are located within the United Kingdom. Carefully analyze the context and the question to provide a well-reasoned answer. Given the fields `context`, `question`, produce the fields `answer` while ensuring your reasoning is clear and concise.\n",
      "\n",
      "5: In a high-stakes trivia competition where every question counts towards your team's success, you are tasked with answering a critical question based on the provided context. Using the context, analyze the information carefully and formulate a clear and concise answer to the question. Remember to explain your reasoning step by step to ensure your answer is well-supported. \n",
      "\n",
      "Given the fields `context` and `question`, produce the fields `answer` and `rationale`.\n",
      "\n",
      "6: You are a knowledgeable trivia expert who specializes in pop culture and film history. Given the fields `context` and `question`, analyze the information provided and produce a well-reasoned `answer` that accurately responds to the question based on the context.\n",
      "\n",
      "7: Given the provided `context` and `question`, analyze the information step by step to extract relevant details and produce a concise and accurate `answer`. Ensure that your reasoning is clear and justifiable based on the information in the context.\n",
      "\n",
      "8: In a high-stakes trivia competition where you must answer questions correctly to win a grand prize, your task is to analyze the provided context and accurately respond to the question. Given the fields `context` and `question`, produce a concise and precise `answer` that demonstrates your understanding and reasoning based on the context. Remember, clarity and accuracy are essential to secure your victory!\n",
      "\n",
      "9: Given the provided `context` about an individual and a specific `question`, analyze the information step by step to produce a clear and accurate `answer`.\n",
      "\n",
      "10: Propose a detailed instruction that guides the Language Model to analyze the context and question thoroughly, ensuring it provides a well-reasoned answer. \n",
      "\n",
      "---\n",
      "\n",
      "PROPOSED INSTRUCTION: \n",
      "\n",
      "\"Using the provided `context` and `question`, carefully analyze the information to extract relevant details. Start by identifying key entities and concepts mentioned in the context that relate to the question. Then, think through the relationships and comparisons necessary to derive a logical answer. Finally, synthesize your findings into a clear and concise response, making sure to explain your reasoning process step by step. Output the final answer along with a brief rationale explaining how you arrived at it.\n",
      "\n",
      "11: You are a knowledgeable trivia expert. Given the fields `context` and `question`, carefully analyze the information provided, reason step by step, and produce the fields `answer` along with a rationale explaining your thought process.\n",
      "\n",
      "12: Given the provided context and question, analyze the information step by step to identify the relevant details that lead to a well-reasoned answer. Focus on extracting key relationships and facts from the context to formulate a precise response to the question asked.\n",
      "\n",
      "13: Given the provided `context` and `question`, analyze the information step by step to determine which entity or publication is most recent. Produce a well-reasoned `answer` that clearly states your conclusion based on the context.\n",
      "\n",
      "14: You are an expert trivia assistant. Given the fields `context` and `question`, analyze the information step by step and produce a concise and accurate `answer`.\n",
      "\n",
      "15: Given the provided context and question, please analyze the information step-by-step to generate a clear and concise answer. Make sure to include your reasoning process in the output.\n",
      "\n",
      "16: Given the provided `context` and `question`, analyze the information step-by-step to extract relevant details and produce a clear and concise `answer`. Ensure that your reasoning is logical and that you validate the connections between the context and the question to arrive at an accurate conclusion.\n",
      "\n",
      "17: Given the provided `context` about films and the `question` regarding their release order, analyze the information step-by-step to produce a well-reasoned `answer` that identifies which film was created first.\n",
      "\n",
      "18: Given the provided context and question, generate a detailed answer that includes a clear rationale explaining how you arrived at the conclusion. Be sure to utilize the context effectively to support your reasoning and provide a comprehensive response that clarifies any relevant relationships or comparisons.\n",
      "\n",
      "19: You are an expert trivia assistant. Given the fields `context` and `question`, analyze the information provided and produce a clear and concise `answer` based on the relevant details from the context.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating the default program...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 50  (44.0): 100%|██████████| 50/50 [00:34<00:00,  1.44it/s]\n",
      "/mnt/ssd4/lm_compiler/my_env/lib/python3.12/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default program score: 44.0\n",
      "\n",
      "==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "In this step, we will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination. Bayesian Optimization will be used for this search process.\n",
      "\n",
      "== Minibatch Trial 1 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:22<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 12', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 8', 'Predictor 2: Few-Shot Set 4', 'Predictor 3: Instruction 3', 'Predictor 3: Few-Shot Set 13'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 2 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 25  (52.0): 100%|██████████| 25/25 [00:20<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 52.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 7', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 15'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 3 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 15 / 25  (60.0): 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 60.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 17', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 2', 'Predictor 3: Few-Shot Set 16'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 4 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 8', 'Predictor 2: Instruction 1', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 17', 'Predictor 3: Few-Shot Set 3'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 5 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 25  (52.0): 100%|██████████| 25/25 [00:22<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 52.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 10', 'Predictor 1: Few-Shot Set 3', 'Predictor 2: Instruction 2', 'Predictor 2: Few-Shot Set 12', 'Predictor 3: Instruction 13', 'Predictor 3: Few-Shot Set 5'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 6 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 9', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 12', 'Predictor 3: Instruction 6', 'Predictor 3: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 7 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 25  (44.0): 100%|██████████| 25/25 [00:14<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 44.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 6', 'Predictor 2: Instruction 16', 'Predictor 2: Few-Shot Set 10', 'Predictor 3: Instruction 3', 'Predictor 3: Few-Shot Set 12'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 8 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 25  (56.0): 100%|██████████| 25/25 [00:20<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 56.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 12', 'Predictor 1: Few-Shot Set 5', 'Predictor 2: Instruction 11', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 12', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 9 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 25  (20.0): 100%|██████████| 25/25 [00:24<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 20.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 19', 'Predictor 2: Instruction 12', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 1', 'Predictor 3: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 10 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 25  (52.0): 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 52.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 8', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 15', 'Predictor 3: Instruction 7', 'Predictor 3: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "===== Full Eval 1 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 60.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0): 100%|██████████| 50/50 [00:30<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mBest full eval score so far!\u001b[0m Score: 48.0\n",
      "=======================\n",
      "\n",
      "\n",
      "== Minibatch Trial 11 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 25  (48.0): 100%|██████████| 25/25 [00:13<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 48.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 17', 'Predictor 2: Instruction 5', 'Predictor 2: Few-Shot Set 2', 'Predictor 3: Instruction 2', 'Predictor 3: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 12 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 25  (52.0): 100%|██████████| 25/25 [00:19<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 52.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 17', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 7', 'Predictor 3: Instruction 15', 'Predictor 3: Few-Shot Set 16'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 13 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 25  (44.0): 100%|██████████| 25/25 [00:15<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 44.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 10', 'Predictor 1: Few-Shot Set 10', 'Predictor 2: Instruction 11', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 19', 'Predictor 3: Few-Shot Set 10'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 14 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 25  (40.0): 100%|██████████| 25/25 [00:23<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 8', 'Predictor 1: Few-Shot Set 1', 'Predictor 2: Instruction 11', 'Predictor 2: Few-Shot Set 12', 'Predictor 3: Instruction 12', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 15 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 25  (56.0): 100%|██████████| 25/25 [00:21<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 56.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 11', 'Predictor 1: Few-Shot Set 5', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 5', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 16 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 25  (32.0): 100%|██████████| 25/25 [00:16<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 12', 'Predictor 1: Few-Shot Set 14', 'Predictor 2: Instruction 11', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 2', 'Predictor 3: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 17 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 25  (44.0): 100%|██████████| 25/25 [00:17<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 44.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 12', 'Predictor 1: Few-Shot Set 5', 'Predictor 2: Instruction 10', 'Predictor 2: Few-Shot Set 3', 'Predictor 3: Instruction 18', 'Predictor 3: Few-Shot Set 9'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 18 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 25  (32.0): 100%|██████████| 25/25 [00:23<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 17', 'Predictor 2: Instruction 7', 'Predictor 2: Few-Shot Set 9', 'Predictor 3: Instruction 1', 'Predictor 3: Few-Shot Set 16'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 19 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 25  (40.0): 100%|██████████| 25/25 [00:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 2', 'Predictor 2: Instruction 12', 'Predictor 2: Few-Shot Set 16', 'Predictor 3: Instruction 10', 'Predictor 3: Few-Shot Set 16'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 20 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 25  (44.0): 100%|██████████| 25/25 [00:18<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 44.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 13', 'Predictor 2: Instruction 15', 'Predictor 2: Few-Shot Set 8', 'Predictor 3: Instruction 4', 'Predictor 3: Few-Shot Set 19'].\n",
      "\n",
      "\n",
      "===== Full Eval 2 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 56.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 50  (44.0): 100%|██████████| 50/50 [00:14<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full eval score: 44.0\n",
      "Best full eval score so far: 48.0\n",
      "=======================\n",
      "\n",
      "\n",
      "== Minibatch Trial 21 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 25  (16.0): 100%|██████████| 25/25 [00:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 16.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 15', 'Predictor 1: Few-Shot Set 5', 'Predictor 2: Instruction 11', 'Predictor 2: Few-Shot Set 6', 'Predictor 3: Instruction 12', 'Predictor 3: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 22 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 25  (44.0): 100%|██████████| 25/25 [00:24<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 44.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 16', 'Predictor 1: Few-Shot Set 5', 'Predictor 2: Instruction 17', 'Predictor 2: Few-Shot Set 14', 'Predictor 3: Instruction 8', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 23 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 25  (40.0): 100%|██████████| 25/25 [00:25<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 3', 'Predictor 2: Instruction 0', 'Predictor 2: Few-Shot Set 13', 'Predictor 3: Instruction 11', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 24 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 25  (44.0): 100%|██████████| 25/25 [00:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 44.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 12', 'Predictor 2: Instruction 18', 'Predictor 2: Few-Shot Set 19', 'Predictor 3: Instruction 2', 'Predictor 3: Few-Shot Set 16'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 25 / 25 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 25  (40.0): 100%|██████████| 25/25 [00:19<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 11', 'Predictor 1: Few-Shot Set 18', 'Predictor 2: Instruction 1', 'Predictor 2: Few-Shot Set 18', 'Predictor 3: Instruction 14', 'Predictor 3: Few-Shot Set 11'].\n",
      "\n",
      "\n",
      "===== Full Eval 3 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 56.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0): 100%|██████████| 50/50 [00:23<00:00,  2.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full eval score: 48.0\n",
      "Best full eval score so far: 48.0\n",
      "=======================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy.evaluate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, MIPROv2\n",
    "prmopt_model = dspy.OpenAI(model='gpt-4o-mini', max_tokens=1000)\n",
    "dspy.settings.configure(lm=prmopt_model)\n",
    "bootstrap_optimizer = MIPROv2(\n",
    "    prompt_model=prmopt_model,\n",
    "    metric=dspy.evaluate.answer_exact_match,\n",
    "    num_candidates=20,\n",
    "    num_threads=8,\n",
    ")\n",
    "optimized_matplot = bootstrap_optimizer.compile(\n",
    "    agent,\n",
    "    trainset=trainset,\n",
    "    max_bootstrapped_demos=2,\n",
    "    max_labeled_demos=2,\n",
    "    num_trials=25,\n",
    "    valset=valset,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 50  (44.0): 100%|██████████| 50/50 [00:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ceb15 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ceb15 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ceb15_row0_col0, #T_ceb15_row0_col1, #T_ceb15_row0_col2, #T_ceb15_row0_col3, #T_ceb15_row0_col4, #T_ceb15_row0_col5, #T_ceb15_row0_col6, #T_ceb15_row1_col0, #T_ceb15_row1_col1, #T_ceb15_row1_col2, #T_ceb15_row1_col3, #T_ceb15_row1_col4, #T_ceb15_row1_col5, #T_ceb15_row1_col6, #T_ceb15_row2_col0, #T_ceb15_row2_col1, #T_ceb15_row2_col2, #T_ceb15_row2_col3, #T_ceb15_row2_col4, #T_ceb15_row2_col5, #T_ceb15_row2_col6, #T_ceb15_row3_col0, #T_ceb15_row3_col1, #T_ceb15_row3_col2, #T_ceb15_row3_col3, #T_ceb15_row3_col4, #T_ceb15_row3_col5, #T_ceb15_row3_col6, #T_ceb15_row4_col0, #T_ceb15_row4_col1, #T_ceb15_row4_col2, #T_ceb15_row4_col3, #T_ceb15_row4_col4, #T_ceb15_row4_col5, #T_ceb15_row4_col6 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ceb15\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ceb15_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_ceb15_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_ceb15_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_ceb15_level0_col3\" class=\"col_heading level0 col3\" >rationale</th>\n",
       "      <th id=\"T_ceb15_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_ceb15_level0_col5\" class=\"col_heading level0 col5\" >context</th>\n",
       "      <th id=\"T_ceb15_level0_col6\" class=\"col_heading level0 col6\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ceb15_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ceb15_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_ceb15_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_ceb15_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_ceb15_row0_col3\" class=\"data row0 col3\" >determine the answer. The context provides information about Cangzhou, stating that it is a prefecture-level city in eastern Hebei province, People's Republic of China. However,...</td>\n",
       "      <td id=\"T_ceb15_row0_col4\" class=\"data row0 col4\" >no</td>\n",
       "      <td id=\"T_ceb15_row0_col5\" class=\"data row0 col5\" >['Cangzhou | \"Cangzhou Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"\"or metro\"\")...</td>\n",
       "      <td id=\"T_ceb15_row0_col6\" class=\"data row0 col6\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ceb15_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ceb15_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_ceb15_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_ceb15_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_ceb15_row1_col3\" class=\"data row1 col3\" >determine who conducts the draft. The context mentions the \"2017 NHL Expansion Draft,\" which was conducted by the National Hockey League (NHL) to fill the...</td>\n",
       "      <td id=\"T_ceb15_row1_col4\" class=\"data row1 col4\" >National Hockey League (NHL)</td>\n",
       "      <td id=\"T_ceb15_row1_col5\" class=\"data row1 col5\" >['\"Marc-André Fleury\" | \"route to a Stanley Cup championship victory, defeating the Nashville Predators in six games. The win was the third Stanley Cup of...</td>\n",
       "      <td id=\"T_ceb15_row1_col6\" class=\"data row1 col6\" ><class 'str'></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ceb15_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ceb15_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_ceb15_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_ceb15_row2_col2\" class=\"data row2 col2\" >{'2006–07 Detroit Red Wings season', 'Steve Yzerman'}</td>\n",
       "      <td id=\"T_ceb15_row2_col3\" class=\"data row2 col3\" >determine the answer. The context provides information about Steve Yzerman, who is a Canadian former professional ice hockey player and served as the captain of...</td>\n",
       "      <td id=\"T_ceb15_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_ceb15_row2_col5\" class=\"data row2 col5\" >['\"Steve Yzerman\" | \"Steve Yzerman Stephen Gregory Yzerman (; born May 9, 1965) is a Canadian former professional ice hockey player who spent his entire...</td>\n",
       "      <td id=\"T_ceb15_row2_col6\" class=\"data row2 col6\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ceb15_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ceb15_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_ceb15_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_ceb15_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_ceb15_row3_col3\" class=\"data row3 col3\" >determine the answer. The context provided does not mention any specific river associated with Crichton Collegiate Church. It primarily focuses on the church's location, its...</td>\n",
       "      <td id=\"T_ceb15_row3_col4\" class=\"data row3 col4\" >The context does not provide information about a river near Crichton Collegiate Church.</td>\n",
       "      <td id=\"T_ceb15_row3_col5\" class=\"data row3 col5\" >['\"Crichton Collegiate Church\" | \"Crichton Collegiate Church Crichton Collegiate Church is situated about south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself...</td>\n",
       "      <td id=\"T_ceb15_row3_col6\" class=\"data row3 col6\" ><class 'str'></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ceb15_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ceb15_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_ceb15_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_ceb15_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
       "      <td id=\"T_ceb15_row4_col3\" class=\"data row4 col3\" >determine the answer. The context provides information about Ealhswith, who was the wife of King Alfred the Great. It states that Ealhswith and Alfred had...</td>\n",
       "      <td id=\"T_ceb15_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
       "      <td id=\"T_ceb15_row4_col5\" class=\"data row4 col5\" >['Ealhswith | \"is commemorated in two early tenth century manuscripts as \"\"the true and dear lady of the English\"\". Ealhswith had a brother called Æthelwulf,...</td>\n",
       "      <td id=\"T_ceb15_row4_col6\" class=\"data row4 col6\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7ca1c05ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_matplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('retrieve', <dspy.retrieve.retrieve.Retrieve object at 0x7f7cb84ce2d0>), ('generate_query[0]', Predict(StringSignature(context, question -> rationale, search_query\n",
      "    instructions='Given the fields `context`, `question`, produce the fields `search_query`.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the search_query}. We ...', '__dspy_field_type': 'output'})\n",
      "    search_query = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Search Query:', 'desc': '${search_query}'})\n",
      "))), ('generate_query[1]', Predict(StringSignature(context, question -> rationale, search_query\n",
      "    instructions='Given the fields `context`, `question`, produce the fields `search_query`.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the search_query}. We ...', '__dspy_field_type': 'output'})\n",
      "    search_query = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Search Query:', 'desc': '${search_query}'})\n",
      "))), ('generate_answer', Predict(StringSignature(context, question -> rationale, answer\n",
      "    instructions='Given the fields `context`, `question`, produce the fields `answer`.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
      ")))]\n"
     ]
    }
   ],
   "source": [
    "optimized_matplot.save('optimized_qa.dspy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_matplot('Are both Cangzhou and Qionghai in the Hebei province of China?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
