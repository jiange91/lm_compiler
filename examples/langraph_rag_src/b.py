from pydantic import BaseModel, Field
from typing import Union
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import json
from compiler.utils import load_api_key
load_api_key('secrets.toml')
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'examples'))

from kalmv import kalmv_semantic
from doc_filter import doc_filter_semantic
from langchain_openai import ChatOpenAI
from devtools import pprint

class AgentMeta(BaseModel):
    """Information about each agent"""
    inputs: list[str] = Field(
        description="list of inputs for the agent"
    )
    outputs: list[str] = Field(
        description="list of outputs for the agent"
    )
    prompt: str = Field(
        description="refined prompt for the agent"
    )
    next_action: Union[str, list[str]] = Field(
        description="next agents to invoke or python code for dynamic decision"
    )
    
class NewAgents(BaseModel):
    """New agent system"""
    agents: dict[str, AgentMeta] = Field(
        description="dictionary of agent name to information about that agent"
    )

# print(NewAgents.schema_json(indent=4))

with open('a.json', 'r') as f:
    json_agents = json.load(f)
    new_agents = NewAgents.parse_obj(json_agents)
    

output_refine_system = """
You are an expert at designing LLM multi-agent workflow. Your team just re-wrote a single-agent system into a multi-agent system but haven't finalized it yet. Now, you need to align the new system to the functionality of the original system.

You will be provided with both information for the old single-agent system and the new multi-agent system.

You should check if the output of old-system can be generated by the new system no matter what code path is taken. If not, make necessary changes to the output varaible of new agents.

Also you should decide the output json schema for each agent in the new system. If agents are providing part of the final output (maybe in a different schema format), you need to aggregate them to align with the single-agent systen's output schema, you should decide how to combine them using python code. If you think no aggregation logic is needed, just put 'None' for this. Make sure that at the end of the execution of the new system, the final output is compatible with the original output schema.

Here's an example:

## Information of the old single-agent system
{
    "agent_prompt": "\nYou are a grader assessing relevance of a retrieved document to a user question.\nIf the document either 1. does not contains semantic meaning related to the user question, or 2. contains toxic content.\n You should give it a binary score 'no' to reject the document, otherwise 'yes'.",
    "input_varaibles": [
        "sub_question",
        "doc_for_filter"
    ],
    "output_schema": {
        "title": "GradeDocuments",
        "description": "Binary score for relevance check on retrieved documents.",
        "type": "object",
        "properties": {
            "binary_score": {
                "title": "Binary Score",
                "description": "Documents are relevant to the question, 'yes' or 'no'",
                "type": "string"
            }
        },
        "required": [
            "binary_score"
        ]
    }
}

You can see this agent takes as input a sub-question and a document to filter. It gives a single binary score as output. The variable name for this agent's output is "binary_score". So you need to make sure the new system should also always generate this output variable in all code paths.

## Information of the suggested multi-agent system 
{
    "agents": {
        "Relevance Evaluation Agent": {
            "inputs": [
                "sub_question",
                "doc_for_filter"
            ],
            "outputs": [
                "relevance_score"
            ],
            "prompt": "Your role is to evaluate the relevance of the provided document to the user question. If the knowledge is irrelevant to the question, grade it as 'No'. If the knowledge is relevant, pass the evaluation to the next agent.",
            "next_action": "def next_agent(relevance_score): return ['END'] if relevance_score == 'no' else ['Toxic Moderation Agent']"
        },
        "Toxic Moderation Agent": {
            "inputs": [
                "doc_for_filter"
            ],
            "outputs": [
                "binary_score"
            ],
            "prompt": "You are responsible for assessing whether the provided document contains toxic content. Answer with 'yes' if the document is toxic, otherwise 'no'.",
            "next_action": "END"
        }
    }
}

Let me explain the information format for the new multi-agent system first. Overall it presents a dictionary of agent names to information about that agent.

Each agent has a list of inputs/output varaible names, a prompt, and a "next_action" field. The next_action field can be a list of agents to invoke next or python code for dynamic decision. 

Specifically for "next_action" field,
'END' is a special keyword to indicate that: along this path, there will be no more agents to invoke. This does not mean the system will end immediately, the system will end when there are no more agents in execution.

## Solution
As you can see this new design has a big problem, the relevance evaluation agent will dynamically decide the next agent to invoke. If it decides to end, the output "binary_score" required by the old system, will not be generated since the current output variable name for this agent is "relevance_score". 

Because this output has the same semantic meaning of the required output, your fix is simple - change the output variable name of the relevance evaluation agent to "binary_score". 

so final aggregator function is "None" in this case.

Here's the example output schema for each agent in the new system after fix:

For Relevance Evaluation Agent:
{
    "title": "RelevanceScoreSchema",
    "description": "Binary score for relevance check on retrieved documents.",
    "type": "object",
    "properties": {
        "binary_score": {
            "title": "Binary Score",
            "description": "Documents are relevant to the question, 'yes' or 'no'",
            "type": "string"
        }
    },
    "required": [
        "binary_score"
    ]
}

For Toxic Moderation Agent:
{
    "title": "ToxicScoreSchema",
    "description": "Binary score for toxicity check on retrieved documents.",
    "type": "object",
    "properties": {
        "binary_score": {
            "title": "Binary Score",
            "description": "Documents are toxic, 'yes' or 'no'",
            "type": "string"
        }
    },
    "required": [
        "binary_score"
    ]
}

You should generate valid json schema for each agent. Their output variables should be included as top-level properties in the schema. You are free to use any descriptive title and description for the schema.

Let me give you another example that require more complex changes:

## Information of the old single-agent system
{
    "agent_prompt": "You are an expert at reviewing research papers. You are tasked with evaluating the presentation and novelty of each paper.",
    "input_varaibles": [
        "papers"
    ],
    "output_json_schema": {
        "title": "PaperReviews",
        "description": "Reviews a list of research papers",
        "type": "object",
        "properties": {
            "scores": {
                "title": "Scores",
                "description": "dictionary of paper title to its score",
                "type": "object",
                "additionalProperties": {
                    "$ref": "#/definitions/Score"
                }
            }
        },
        "required": [
            "scores"
        ],
        "definitions": {
            "Score": {
                "title": "Score",
                "description": "Ratings of a research paper",
                "type": "object",
                "properties": {
                    "presentation": {
                        "title": "Presentation",
                        "description": "Presentation of the research paper",
                        "type": "integer"
                    },
                    "novelty": {
                        "title": "Novelty",
                        "description": "Novelty of the research paper",
                        "type": "integer"
                    }
                },
                "required": [
                    "presentation",
                    "novelty"
                ]
            }
        }
    }
}

In this example, the old system takes a list of papers as input and outputs a dictionary of paper title to its score. Each score has two fields: presentation and novelty.

## Information of the suggested multi-agent system
{
    "agents": {
        "Presentation Evaluation Agent": {
            "inputs": [
                "papers"
            ],
            "outputs": [
                "presentation_scores"
            ],
            "prompt": "Your role is to evaluate the presentation of each paper. Output a dictionary of paper title to its presentation score.",
            "next_action": "END"
        },
        "Novelty Evaluation Agent": {
            "inputs": [
                "papers"
            ],
            "outputs": [
                "novelty_scores"
            ],
            "prompt": "Your role is to evaluate the novelty of each paper. Output a dictionary of paper title to its novelty score.",
            "next_action": "END"
        }
    }
}

## Solution
In this case both agent gives their part of outputs and you can't simply rename these variables to the original output keyword because they are semantially different. Instead, you can keep these outputs and write a aggregator function to synthesis the final output. 

You can define the json schema of each agent's output as follows:

For Presentation Evaluation Agent:
{
    "title": "PresentationScoresSchema",
    "description": "Scores for presentation of research papers",
    "type": "object",
    "properties": {
        "presentation_scores": {
            "title": "Presentation Scores",
            "description": "dictionary of paper title to its score",
            "type": "object",
            "additionalProperties": {
                "type": "integer"
            }
        }
    },
    "required": [
        "presentation_scores"
    ]
}

For Novelty Evaluation Agent:
{
    "title": "NoveltyScoresSchema",
    "description": "Scores for novelty of research papers",
    "type": "object",
    "properties": {
        "novelty_scores": {
            "title": "Novelty Scores",
            "description": "dictionary of paper title to its score",
            "type": "object",
            "additionalProperties": {
                "type": "integer"
            }
        }
    },
    "required": [
        "novelty_scores"
    ]
}

Then, you need to write code to combine the outputs of these new agents to generate the final output that is compatible to the orignal final output schema "PaperReviews". You should use their variable name in the function signature as they will be passed as keyword arguments in the future call. The first argument should always be "output_schema", which is a pydantic model class that represents the final output schema.

Also this function need to return a dictionary that is compatible with the final output schema. In this case, the schema is "PaperReviews". so the final dictionary will be something like this:
{
    "scores": {
        "paper1": {"presentation": 5, "novelty": 3},
        "paper2": {"presentation": 4, "novelty": 2}
}

final output aggregator example code:
```python
def combine_outputs(output_schema: PaperReviews, presentation_scores: dict[str, int], novelty_scores: dict[str, int]):
    scores = {}
    for title in presentation_scores:
        scores[title] = {"presentation": presentation_scores[title], "novelty": novelty_scores[title]}
    return output_schema(scores=scores)
```
please omit type hint when you generate the answer, this demonstration is for you to better understand the function signature.
"""
user_prompt = """

Now, this is the real task for you.

## Information of the old single-agent system
{old_semantic}

## Information of the suggested multi-agent system
{new_system}

## Your answer:
"""

class AnyMe(BaseModel):
    imhere: str = Field(
        description="I am here"
    )

class AgentSemantic(BaseModel):
    """Information about each agent"""
    agent_prompt: str = Field(
        description="prompt for the agent"
    )
    inputs_varaibles: list[str] = Field(
        description="list of input variables for the agent"
    )
    output_json_schema: str = Field(
        description="json output schema for the agent"
    )
    next_action: Union[str, list[str]] = Field(
        description="next agents to invoke or python code for dynamic decision"
    )
    anything: AnyMe = Field(
        description="test anything"
    )
    
class StructuredAgentSystem(BaseModel):
    """Refined agent system with structured output schema"""
    agents: dict[str, AgentSemantic] = Field(
        description="dictionary of agent name to information about that agent"
    )
    
    final_output_aggregator_code: str = Field(
        description="python code to combine the outputs of the new agents to generate the final output, put 'None' if not needed"
    )
    
print(json.dumps(json.loads(StructuredAgentSystem.schema_json()), indent=4))
from langchain_core.output_parsers import JsonOutputParser
parser = JsonOutputParser(pydantic_object=StructuredAgentSystem)
print(parser.get_format_instructions())
exit()

interaction_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "{output_refine_system}"),
        ("human", user_prompt),
    ]
).partial(output_refine_system=output_refine_system)

def refine_kernel():
    llm = ChatOpenAI(model="gpt-4o", temperature=0.0)
    routine = interaction_prompt | llm | StrOutputParser()
    new_interaction = routine.invoke({
        "old_semantic": kalmv_semantic.get_formatted_info(),
        "new_system": new_agents.json(),
        }
    )
    print(new_interaction)
    interaction_prompt.extend(
        [
            ("ai", "{new_interaction}"),
            ("human", "Now please reformat the new agent system to the desired JSON format.\n{format_instructions}"),
        ]
    )
    
    sllm = ChatOpenAI(model="gpt-4o", temperature=0.0).with_structured_output(StructuredAgentSystem, method="json_mode")
    reformater = interaction_prompt | sllm
    soutput = reformater.invoke({
        "old_semantic": kalmv_semantic.get_formatted_info(),
        "new_system": new_agents.json(),
        "new_interaction": new_interaction,
        "format_instructions": parser.get_format_instructions(),
        }
    )
    pprint(soutput)
    return soutput

# refine_kernel()

from compiler.IR.schema_parser import json_schema_to_pydantic_model
with open('test_write.json', 'r') as f:
    json_agents = json.load(f)
    
cls = json_schema_to_pydantic_model(json_agents, 'examples/langraph_rag_src/compile_log/struct_agent_system.py')

print(json.dumps(json.loads(cls.schema_json()), indent=4))
 