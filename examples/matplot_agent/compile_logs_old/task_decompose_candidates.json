{
    "query expansion": {
        "score": 4,
        "rationale": "Prompt 1 requires the agent to understand the user's query, which can be complex and multifaceted. The agent must then decompose the query into detailed, step-by-step instructions, including identifying appropriate libraries and functions, setting parameters correctly, and ensuring the code is executable. This involves multi-step reasoning, planning, and decision-making, and at least one sub-task (understanding the query and translating it into detailed instructions) is non-trivial."
    },
    "initial code generation": {
        "score": 3,
        "rationale": "Prompt 2 involves generating runnable Python code from a natural language query. While this requires vertical planning, reasoning, and decision-making, the sub-tasks (such as choosing libraries and writing code) are relatively straightforward for a capable code generation LLM. The task is clear and does not involve significant ambiguity or complex decomposition."
    },
    "plot debugger": {
        "score": 3,
        "rationale": "Prompt 3 requires the agent to fix errors in existing code based on a natural language query and an error message. This involves understanding the error, diagnosing the problem, and generating a fix. While this requires vertical reasoning and decision-making, the sub-tasks (error diagnosis and code correction) are generally straightforward for a capable LLM."
    },
    "visual refine coder": {
        "score": 3,
        "rationale": "Prompt 4 involves improving existing code based on natural language instructions. The agent must understand the instructions, retain the original functionality, and make the necessary improvements. This requires vertical planning, reasoning, and decision-making, but the sub-tasks (understanding instructions and modifying code) are relatively straightforward for a capable LLM."
    }
}