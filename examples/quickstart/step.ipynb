{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================\n",
    "# Evaluator\n",
    "#================================================================\n",
    "\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(s):\n",
    "    # Normalize Unicode characters\n",
    "    s = unicodedata.normalize('NFD', s)\n",
    "    # Convert to lowercase\n",
    "    s = s.lower()\n",
    "    # Remove punctuation\n",
    "    s = ''.join(ch for ch in s if ch not in string.punctuation)\n",
    "    # Remove articles (a, an, the)\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    # Fix extra whitespaces\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "\n",
    "def f1_score_strings(label, pred):\n",
    "    # Tokenize the strings (split by whitespace)\n",
    "    tokens1 = set(normalize_text(label).split())\n",
    "    tokens2 = set(normalize_text(pred).split())\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = len(tokens1 & tokens2)\n",
    "    false_positives = len(tokens2 - tokens1)\n",
    "    false_negatives = len(tokens1 - tokens2)\n",
    "\n",
    "    if true_positives == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================\n",
    "# Data Loader\n",
    "#================================================================\n",
    "\n",
    "import json\n",
    "\n",
    "def load_data_minor():\n",
    "    with open(\"data._json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    # raw format:\n",
    "    # [\n",
    "    #     {\n",
    "    #         \"question\": \"...\",\n",
    "    #         \"docs\": [...],\n",
    "    #         \"answer\": \"...\"\n",
    "    #     },\n",
    "    #     ...\n",
    "    # ]\n",
    "          \n",
    "    # format to (input, output) pairs\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        input = (d[\"question\"], d[\"docs\"])\n",
    "        output = d[\"answer\"]\n",
    "        new_data.append((input, output))\n",
    "    return new_data[:5], None, new_data[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================\n",
    "# Optimizer Set Up\n",
    "#================================================================\n",
    "\n",
    "from cognify.optimizer.core import driver, flow\n",
    "from cognify.cog_hub import reasoning, ensemble\n",
    "from cognify.cog_hub.common import NoChange\n",
    "from cognify.cog_hub.fewshot import LMFewShot\n",
    "from cognify.cog_hub.reasoning import ZeroShotCoT\n",
    "from cognify.optimizer.control_param import ControlParameter\n",
    "\n",
    "# ================= Inner Loop Config =================\n",
    "# Reasoning Parameter\n",
    "reasoning_param = reasoning.LMReasoning(\n",
    "    [NoChange(), ZeroShotCoT()] \n",
    ")\n",
    "# Few Shot Parameter\n",
    "few_shot_params = LMFewShot(2)\n",
    "\n",
    "# Layer Config\n",
    "inner_opt_config = flow.OptConfig(\n",
    "    n_trials=2,\n",
    ")\n",
    "inner_loop_config = driver.LayerConfig(\n",
    "    layer_name='inner_loop',\n",
    "    universal_params=[few_shot_params, reasoning_param],\n",
    "    opt_config=inner_opt_config,\n",
    ")\n",
    "\n",
    "# ================= Outer Loop Config =================\n",
    "# Ensemble Parameter\n",
    "general_usc_ensemble = ensemble.UniversalSelfConsistency(3)\n",
    "general_ensemble_params = ensemble.ModuleEnsemble(\n",
    "    [NoChange(), general_usc_ensemble]\n",
    ")\n",
    "# Layer Config\n",
    "outer_opt_config = flow.OptConfig(\n",
    "    n_trials=2,\n",
    ")\n",
    "outer_loop_config = driver.LayerConfig(\n",
    "    layer_name='outer_loop',\n",
    "    universal_params=[general_ensemble_params],\n",
    "    opt_config=outer_opt_config,\n",
    ")\n",
    "\n",
    "# ================= Overall Control Parameter =================\n",
    "optimize_control_param = ControlParameter(\n",
    "    opt_layer_configs=[outer_loop_config, inner_loop_config],\n",
    "    opt_history_log_dir='opt_results',\n",
    "    evaluator_batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = load_data_minor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e4fb679c0c4b0cafe0335bcb5a1af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "> Evaluation in dry_run | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05edafc0c0d04a1992e6cfb8f6ea45fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "> outer_loop | (best score: 0.00, lowest cost@1000: 0.00 $):   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b69acc41834ecb8ece30654d572597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "------> Evaluation in outer_loop_0 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0/5 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec50c171170946e4bcc4fb5e4649665b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "------> Evaluation in outer_loop_1 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0/5 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55fed5ef8104cd6b84333c31977ca11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "---> inner_loop in outer_loop_0 | (best score: 0.00, lowest cost@1000: 0.00 $):   0%|          | 0/2 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ea8b8e29f546278c8f0da2006dc060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "---> inner_loop in outer_loop_1 | (best score: 0.00, lowest cost@1000: 0.00 $):   0%|          | 0/2 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05adf79f66fc4fd9991fd26889e12e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "------> Evaluation in outer_loop_0.inner_loop_1 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3222df3610a4d12bf4eee5f8a4659fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "------> Evaluation in outer_loop_0.inner_loop_0 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6cc2ac3ff94034b87155d8adcd0255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "------> Evaluation in outer_loop_1.inner_loop_0 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbca84b2e52e459386037e057774bb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "------> Evaluation in outer_loop_1.inner_loop_1 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-11-14 05:09:02] ----------------- Optimization Finished -----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Optimization Results ===========\n",
      "Num Pareto Frontier: 1\n",
      "--------------------------------------------------------\n",
      "Pareto_1\n",
      "  Quality: 0.402, Cost per 1K invocation ($): 0.17\n",
      "  Applied Optimization: outer_loop_0.inner_loop_1\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "import cognify.run.optimize\n",
    "\n",
    "opt_cost, pareto_frontier, opt_logs = cognify.run.optimize.optimize(\n",
    "    script_path=\"cognify_workflow.py\",\n",
    "    control_param=optimize_control_param,\n",
    "    train_set=train,\n",
    "    val_set=val,\n",
    "    eval_fn=f1_score_strings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognify.run.evaluate import evaluate, load_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_workflow = load_workflow(control_param=optimize_control_param, config_id='Pareto_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The population of Woodmere, New York in 2010 was 17,121.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = (\n",
    "    \"What was the 2010 population of the birthplace of Gerard Piel?\", \n",
    "    [\n",
    "        'Gerard Piel | Gerard Piel (1 March 1915 in Woodmere, N.Y. – 5 September 2004) was the publisher of the new Scientific American magazine starting in 1948. He wrote for magazines, including \"The Nation\", and published books on science for the general public. In 1990, Piel was presented with the \"In Praise of Reason\" award by the Committee for Skeptical Inquiry (CSICOP).',\n",
    "        'Woodmere, New York | Woodmere is a hamlet and census-designated place (CDP) in Nassau County, New York, United States. The population was 17,121 at the 2010 census.',\n",
    "    ],\n",
    ")\n",
    "\n",
    "new_workflow(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Testing select trial outer_loop_0.inner_loop_1 -----\n",
      "  Params: {'qa_agent_few_shot': 'NoChange', 'qa_agent_reasoning': 'NoChange'}\n",
      "  Quality: 0.402, Cost per 1K invocation ($): 0.17 $\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a820343e8a1b42589cf5dc6ba0513f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "> Evaluation in outer_loop_0.inner_loop_1 | (avg score: 0.00, avg cost@1000: 0.00 $):   0%|          | 0/10 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Evaluation Results ===========\n",
      "  Quality: 0.453, Cost per 1K invocation ($): 0.16 $\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate(\n",
    "    control_param=optimize_control_param,\n",
    "    config_id='Pareto_1',\n",
    "    test_set=test,\n",
    "    n_parallel=10,\n",
    "    eval_fn=f1_score_strings,\n",
    "    save_to='eval_results.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
